{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f62dc73-df18-4548-bc0d-aea2a125fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import statsmodels.stats.multitest\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# disable warnings, use w caution\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# project specific libs\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b42930-bcde-48f3-9753-8779e1aa11fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project specific path\n",
    "path = '/Users/KevinBu/Desktop/clemente_lab/Projects/oa/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3013747-2e0e-412a-b719-b2a6a28afbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BarcodeSequence</th>\n",
       "      <th>LinkerPrimerSequence</th>\n",
       "      <th>Separate</th>\n",
       "      <th>Timepoint</th>\n",
       "      <th>Together</th>\n",
       "      <th>ContactEmail</th>\n",
       "      <th>ContactName</th>\n",
       "      <th>PrimaryInvestigator</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>RawDataNotes</th>\n",
       "      <th>...</th>\n",
       "      <th>broccoli</th>\n",
       "      <th>Garbanzo_beans</th>\n",
       "      <th>pork</th>\n",
       "      <th>beef</th>\n",
       "      <th>burger</th>\n",
       "      <th>Total_omega3</th>\n",
       "      <th>Adherence_omega3</th>\n",
       "      <th>Total_omega6</th>\n",
       "      <th>Adherence_omega6</th>\n",
       "      <th>Total_o3_o6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#SampleID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OAD-001.pre.stool</th>\n",
       "      <td>TTCAGTTCGTTA</td>\n",
       "      <td>CCGGACTACHVGGGTWTCTAAT</td>\n",
       "      <td>All</td>\n",
       "      <td>pre</td>\n",
       "      <td>OAD-001.pre.stool.guma.plate313</td>\n",
       "      <td>rebecca.blank@nyulangone.org</td>\n",
       "      <td>Rebecca Blank</td>\n",
       "      <td>Jose Scher</td>\n",
       "      <td>NonVA</td>\n",
       "      <td>OAD-001.pre.stool.guma.plate313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low adherence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low adherence</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OAD-001.post.stool</th>\n",
       "      <td>CGGCCAGAAGCA</td>\n",
       "      <td>CCGGACTACHVGGGTWTCTAAT</td>\n",
       "      <td>All</td>\n",
       "      <td>post</td>\n",
       "      <td>OAD-001.post.stool.guma.plate313</td>\n",
       "      <td>rebecca.blank@nyulangone.org</td>\n",
       "      <td>Rebecca Blank</td>\n",
       "      <td>Jose Scher</td>\n",
       "      <td>NonVA</td>\n",
       "      <td>OAD-001.post.stool.guma.plate313</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Low adherence</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Low adherence</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OAD-003.pre.stool</th>\n",
       "      <td>GACGTTAAGAAT</td>\n",
       "      <td>CCGGACTACHVGGGTWTCTAAT</td>\n",
       "      <td>All</td>\n",
       "      <td>pre</td>\n",
       "      <td>OAD-003.pre.stool.guma.plate313</td>\n",
       "      <td>rebecca.blank@nyulangone.org</td>\n",
       "      <td>Rebecca Blank</td>\n",
       "      <td>Jose Scher</td>\n",
       "      <td>NonVA</td>\n",
       "      <td>OAD-003.pre.stool.guma.plate313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>Low adherence</td>\n",
       "      <td>53.2</td>\n",
       "      <td>High adherence</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OAD-003.post.stool</th>\n",
       "      <td>TCGCTACAGATG</td>\n",
       "      <td>CCGGACTACHVGGGTWTCTAAT</td>\n",
       "      <td>All</td>\n",
       "      <td>post</td>\n",
       "      <td>OAD-003.post.stool.guma.plate313</td>\n",
       "      <td>rebecca.blank@nyulangone.org</td>\n",
       "      <td>Rebecca Blank</td>\n",
       "      <td>Jose Scher</td>\n",
       "      <td>NonVA</td>\n",
       "      <td>OAD-003.post.stool.guma.plate313</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Low adherence</td>\n",
       "      <td>108.0</td>\n",
       "      <td>High adherence</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OAD-004.pre.stool</th>\n",
       "      <td>ATGGGACCTTCA</td>\n",
       "      <td>CCGGACTACHVGGGTWTCTAAT</td>\n",
       "      <td>All</td>\n",
       "      <td>pre</td>\n",
       "      <td>OAD-004.pre.stool.guma.plate313</td>\n",
       "      <td>rebecca.blank@nyulangone.org</td>\n",
       "      <td>Rebecca Blank</td>\n",
       "      <td>Jose Scher</td>\n",
       "      <td>NonVA</td>\n",
       "      <td>OAD-004.pre.stool.guma.plate313</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>Low adherence</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Low adherence</td>\n",
       "      <td>35.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   BarcodeSequence    LinkerPrimerSequence Separate Timepoint  \\\n",
       "#SampleID                                                                       \n",
       "OAD-001.pre.stool     TTCAGTTCGTTA  CCGGACTACHVGGGTWTCTAAT      All       pre   \n",
       "OAD-001.post.stool    CGGCCAGAAGCA  CCGGACTACHVGGGTWTCTAAT      All      post   \n",
       "OAD-003.pre.stool     GACGTTAAGAAT  CCGGACTACHVGGGTWTCTAAT      All       pre   \n",
       "OAD-003.post.stool    TCGCTACAGATG  CCGGACTACHVGGGTWTCTAAT      All      post   \n",
       "OAD-004.pre.stool     ATGGGACCTTCA  CCGGACTACHVGGGTWTCTAAT      All       pre   \n",
       "\n",
       "                                            Together  \\\n",
       "#SampleID                                              \n",
       "OAD-001.pre.stool    OAD-001.pre.stool.guma.plate313   \n",
       "OAD-001.post.stool  OAD-001.post.stool.guma.plate313   \n",
       "OAD-003.pre.stool    OAD-003.pre.stool.guma.plate313   \n",
       "OAD-003.post.stool  OAD-003.post.stool.guma.plate313   \n",
       "OAD-004.pre.stool    OAD-004.pre.stool.guma.plate313   \n",
       "\n",
       "                                    ContactEmail    ContactName  \\\n",
       "#SampleID                                                         \n",
       "OAD-001.pre.stool   rebecca.blank@nyulangone.org  Rebecca Blank   \n",
       "OAD-001.post.stool  rebecca.blank@nyulangone.org  Rebecca Blank   \n",
       "OAD-003.pre.stool   rebecca.blank@nyulangone.org  Rebecca Blank   \n",
       "OAD-003.post.stool  rebecca.blank@nyulangone.org  Rebecca Blank   \n",
       "OAD-004.pre.stool   rebecca.blank@nyulangone.org  Rebecca Blank   \n",
       "\n",
       "                   PrimaryInvestigator Cohort  \\\n",
       "#SampleID                                       \n",
       "OAD-001.pre.stool           Jose Scher  NonVA   \n",
       "OAD-001.post.stool          Jose Scher  NonVA   \n",
       "OAD-003.pre.stool           Jose Scher  NonVA   \n",
       "OAD-003.post.stool          Jose Scher  NonVA   \n",
       "OAD-004.pre.stool           Jose Scher  NonVA   \n",
       "\n",
       "                                        RawDataNotes  ... broccoli  \\\n",
       "#SampleID                                             ...            \n",
       "OAD-001.pre.stool    OAD-001.pre.stool.guma.plate313  ...      0.0   \n",
       "OAD-001.post.stool  OAD-001.post.stool.guma.plate313  ...      4.0   \n",
       "OAD-003.pre.stool    OAD-003.pre.stool.guma.plate313  ...      0.0   \n",
       "OAD-003.post.stool  OAD-003.post.stool.guma.plate313  ...      4.0   \n",
       "OAD-004.pre.stool    OAD-004.pre.stool.guma.plate313  ...      2.8   \n",
       "\n",
       "                   Garbanzo_beans pork  beef burger Total_omega3  \\\n",
       "#SampleID                                                          \n",
       "OAD-001.pre.stool             0.0  0.0   0.0    0.0          NaN   \n",
       "OAD-001.post.stool            0.0  0.0   0.0    0.0         48.0   \n",
       "OAD-003.pre.stool             0.0  0.0  14.0    0.0         16.8   \n",
       "OAD-003.post.stool            0.0  0.0   0.0    0.0         48.0   \n",
       "OAD-004.pre.stool             0.0  0.0   0.0    0.0          2.8   \n",
       "\n",
       "                   Adherence_omega3 Total_omega6 Adherence_omega6 Total_o3_o6  \n",
       "#SampleID                                                                      \n",
       "OAD-001.pre.stool     Low adherence          NaN    Low adherence         0.0  \n",
       "OAD-001.post.stool    Low adherence         72.0    Low adherence       131.0  \n",
       "OAD-003.pre.stool     Low adherence         53.2   High adherence        75.0  \n",
       "OAD-003.post.stool    Low adherence        108.0   High adherence       171.0  \n",
       "OAD-004.pre.stool     Low adherence         28.0    Low adherence        35.8  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from AC Q2 run of merged saliva stool\n",
    "df_map = pd.read_csv(path + 'inputs/Qiime2_0/qiime_mapping_file.tsv', sep='\\t', index_col=0)\n",
    "q2_row = df_map.loc['#q2:types',:]\n",
    "df_map = df_map.drop('#q2:types')\n",
    "\n",
    "# change index so it matches metadata file\n",
    "df_map.index = df_map.index.map(lambda x: x.split('.guma')[0])\n",
    "\n",
    "# drop MOC and elution buffer\n",
    "df_map = df_map.drop(['MOC.320','elutionbuffer.plate313'])\n",
    "\n",
    "# grab metadata\n",
    "df_meta = pd.read_csv(path + 'inputs/Metadata_OA.csv')\n",
    "\n",
    "# rename 'Run_ID_Saliva' to be correct\n",
    "df_meta['Timepoints'] = df_meta['Timepoints'].apply(lambda x: 'pre' if x == '0' else 'post')\n",
    "df_meta['Patient_ID'] = df_meta['Patient_ID'].apply(lambda x: x[:-3])  \n",
    "df_meta['Study_ID'] = df_meta['Study_ID'].apply(lambda x: x.split('_')[0][-3:]) \n",
    "\n",
    "# create per sample type mapping files\n",
    "type_to_ST = {'saliva':'Saliva','stool':'fecal'}\n",
    "type_to_df_map = {}\n",
    "\n",
    "# split into specimen type\n",
    "for t in type_to_ST:\n",
    "    # subset on specimen type\n",
    "    df_map_type = df_map[df_map['SpecimenType'] == type_to_ST[t]]\n",
    "\n",
    "    # as to not overwrite df meta\n",
    "    df_meta_type = df_meta.copy()\n",
    "\n",
    "    # create new sample ID for specimen type and set as index\n",
    "    df_meta_type['#SampleID'] = df_meta['Patient_ID'] + '-' + df_meta['Study_ID'] + '.' + df_meta['Timepoints'] + '.' + t\n",
    "    df_meta_type = df_meta_type.set_index('#SampleID')\n",
    "\n",
    "    # create full mapping file\n",
    "    df_map_type = pd.concat([df_map_type, df_meta_type],axis=1)\n",
    "\n",
    "    # use only sequenced samples\n",
    "    df_map_type = df_map_type.dropna(how='any',subset='BarcodeSequence')\n",
    "\n",
    "    # drop all na columns\n",
    "    df_map_type = df_map_type.dropna(how='all',axis=1)\n",
    "\n",
    "    # drop VAD OA 015 because misdx with PsA not OA\n",
    "    if t == 'saliva':\n",
    "        df_map_type = df_map_type.drop(['VAOAD-015.pre.saliva','VAOAD-015.post.saliva'])\n",
    "    if t == 'stool':\n",
    "        df_map_type = df_map_type.drop(['VAOAD-015.pre.stool','VAOAD-015.post.stool'])\n",
    "\n",
    "    # populate dict of mapping files\n",
    "    type_to_df_map[t] = df_map_type\n",
    "\n",
    "    # export for q2\n",
    "    df_q2_type = pd.concat([q2_row.to_frame().T, df_map_type])\n",
    "    df_q2_type.index.name = '#SampleID'\n",
    "    df_q2_type.iloc[0,:] = 'categorical'\n",
    "    df_q2_type.to_csv(path + 'inputs/qiime_mapping_file_' + t + '.tsv', sep='\\t')\n",
    "    df_q2_type = df_q2_type[df_q2_type['Adherece_antiinflam'].isin(['Moderate adherence', 'High adherence','categorical'])]\n",
    "    df_q2_type.to_csv(path + 'inputs/qiime_mapping_file_' + t + '_adh.tsv', sep='\\t')\n",
    "\n",
    "type_to_df_map['stool'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95e4ef90-0416-4803-a5b2-d730031630c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['VAS_Pt', 'VAS_overall', 'WOMAC_pain', 'WOMAC_stiffness', 'WOMAC_activity', 'WOMAC_total', 'Pain_DETECT', 'CES_D', 'Helplesness', 'Magnification', 'Rumination', 'PCS_EN', 'Sleep_distrubance', 'PASE_walk', 'PASE_light', 'BMI']\n",
      "all\n",
      "42\n",
      "modhigh\n",
      "32\n",
      "low\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>effect</th>\n",
       "      <th>pval</th>\n",
       "      <th>stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VAS_Pt</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MWU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VAS_overall</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MWU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WOMAC_pain</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MWU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WOMAC_stiffness</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MWU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WOMAC_activity</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MWU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               var effect pval stat\n",
       "0           VAS_Pt      0    1  MWU\n",
       "0      VAS_overall      0    1  MWU\n",
       "0       WOMAC_pain      0    1  MWU\n",
       "0  WOMAC_stiffness      0    1  MWU\n",
       "0   WOMAC_activity      0    1  MWU"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "# Hypothesis 1: There will be a measurable difference in WOMAC pain response scores and \n",
    "# other outcomes from baseline to after the dietary intervention.\n",
    "###\n",
    "\n",
    "# outcome variables\n",
    "outcomes = ['VAS_Pt', 'VAS_overall', 'WOMAC_pain', 'WOMAC_stiffness', 'WOMAC_activity', 'WOMAC_total', 'Pain_DETECT', \n",
    "            'CES_D', 'Helplesness', 'Magnification', 'Rumination', 'PCS_EN', 'Sleep_distrubance', 'PASE_walk', 'PASE_light', \n",
    "            #'PASE_gardening', # Where did this go? gardening_improve is binary\n",
    "            'BMI']\n",
    "\n",
    "\n",
    "# hypothesis 1\n",
    "# create a new df_meta\n",
    "df_meta = pd.read_csv(path + 'inputs/Metadata_OA.csv')\n",
    "\n",
    "# rename 'Run_ID_Saliva' to be correct\n",
    "df_meta['Timepoints'] = df_meta['Timepoints'].apply(lambda x: 'pre' if x == '0' else 'post')\n",
    "df_meta['Patient_ID'] = df_meta['Patient_ID'].apply(lambda x: x[:-3])  \n",
    "df_meta['Study_ID'] = df_meta['Study_ID'].apply(lambda x: x.split('_')[0][-3:]) \n",
    "df_meta['#SampleID'] = df_meta['Patient_ID'] + '-' + df_meta['Study_ID'] + '.' + df_meta['Timepoints'] + '.stool'\n",
    "df_meta = df_meta.set_index('#SampleID')\n",
    "\n",
    "# convert % to floats for calculations down the road\n",
    "bin = []\n",
    "cont = []\n",
    "df_paired_os = []\n",
    "for w in outcomes:\n",
    "    df_w = df_meta[w]\n",
    "    if df_w.nunique() > 2: # do spearman\n",
    "        df_meta[w] = df_meta[w].astype(str).str.replace('%','').astype(float).values\n",
    "        cont.append(w)\n",
    "    else:\n",
    "        bin.append(w)\n",
    "\n",
    "    # compute difference and store it\n",
    "    df_md = df_meta.copy()\n",
    "    df_md['SubjectID'] = df_md['Patient_ID'] + df_md['Study_ID']\n",
    "    \n",
    "    # first drop unpaired samples\n",
    "    s_remove = []\n",
    "    for s in list(df_md['SubjectID'].values):\n",
    "        if len(df_md[df_md['SubjectID'] == s]) != 2:\n",
    "            s_remove.append(s)\n",
    "    df_md = df_md.loc[~df_md['SubjectID'].isin(s_remove),:] # careful not to use ([s_remove])\n",
    "    \n",
    "    # set vars\n",
    "    group_var = 'Timepoints'\n",
    "    pair_var = 'SubjectID'\n",
    "    groups = ['pre','post']\n",
    "    \n",
    "    # get paired per indiv pair\n",
    "    pair_to_diff = {}\n",
    "    for p in list(df_md[pair_var].values):\n",
    "        df = df_md[df_md[pair_var] == p]\n",
    "        t0 = float(df[df[group_var] == groups[0]][w].values)\n",
    "        tf = float(df[df[group_var] == groups[1]][w].values)\n",
    "        pair_to_diff[p] = tf - t0\n",
    "    \n",
    "    df_paired_o = pd.DataFrame.from_dict(pair_to_diff, orient='index', columns=[w + '_diff'])\n",
    "    df_paired_os.append(df_paired_o)\n",
    "\n",
    "df_meta_paired = pd.concat([*df_paired_os], axis=1)    \n",
    "\n",
    "print(bin)\n",
    "print(cont)\n",
    "\n",
    "# split into all and mod high only\n",
    "for a in ['all','modhigh','low']:\n",
    "    print(a)\n",
    "    if a == 'all':\n",
    "        job = 'jobs03'\n",
    "    if a == 'modhigh':\n",
    "        job = 'jobs02'\n",
    "        df_meta = df_meta[df_meta['Adherece_antiinflam'].isin(['Moderate adherence', 'High adherence'])]\n",
    "    if a == 'low':\n",
    "        job = 'jobs02a'\n",
    "        df_meta = df_meta[df_meta['Adherece_antiinflam'] == 'Low adherence']\n",
    "        \n",
    "    print(len(df_meta))\n",
    "    \n",
    "    df_results = pd.DataFrame(columns=['var','effect','pval','stat'])\n",
    "    # do post treatment vals of binary vars differ from pre treatment 'unpaired'\n",
    "    for b in bin:\n",
    "        ct_table_ind=pd.crosstab(df_meta[\"Timepoints\"],df_meta[b])\n",
    "        chi2_stat, p, dof, expected = scipy.stats.chi2_contingency(ct_table_ind)\n",
    "        row=pd.DataFrame.from_dict({'var': [b],'effect':[chi2_stat],'pval':[p],'stat':['chi2']})\n",
    "        df_results = pd.concat([df_results, row])\n",
    "    \n",
    "    # fishers exact\n",
    "    for b in bin:\n",
    "        ct_table_ind=pd.crosstab(df_meta[\"Timepoints\"],df_meta[b])\n",
    "        fisher, p = scipy.stats.fisher_exact(ct_table_ind)\n",
    "        row=pd.DataFrame.from_dict({'var': [b],'effect':[t],'pval':[p],'stat':['fisher']})\n",
    "        df_results = pd.concat([df_results, row])\n",
    "        \n",
    "    # do post treatment vals of continuous vars differ from pre treatment unpaired\n",
    "    df_pre = df_meta[df_meta['Timepoints'] == 'pre']\n",
    "    df_post = df_meta[df_meta['Timepoints'] == 'post']\n",
    "    for c in cont:\n",
    "        try:\n",
    "            W,p = scipy.stats.mannwhitneyu(x=df_pre[c].values,y=df_post[c].values, nan_policy='omit')\n",
    "        except:\n",
    "            W,p = 0, 1\n",
    "        row=pd.DataFrame.from_dict({'var': [c],'effect':[W],'pval':[p],'stat':['mwu']})\n",
    "        if p < 0.05:\n",
    "            ax = sns.boxplot(data=df_meta, x='Timepoints', y=c, orient='v')\n",
    "            sns.swarmplot(data=df_meta, x='Timepoints', y=c, palette='dark:grey', hue=None, orient='v')\n",
    "        \n",
    "            # ax.axes.set_title(\"Title\",fontsize=48)\n",
    "            ax.set_ylabel(c,fontsize=16)\n",
    "            ax.set_xlabel('Timepoints',fontsize=16)                \n",
    "            ax.tick_params(labelsize=16)\n",
    "            sns.despine()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(path + 'outputs/' + job + '/mwu_' + c  + '.pdf')\n",
    "            plt.close()            \n",
    "        row=pd.DataFrame.from_dict({'var': [c],'effect':[W],'pval':[p],'stat':['MWU']})\n",
    "        df_results = pd.concat([df_results, row])\n",
    "        \n",
    "    df_pre = df_meta[df_meta['Timepoints'] == 'pre']\n",
    "    df_post = df_meta[df_meta['Timepoints'] == 'post']\n",
    "    for c in cont:\n",
    "        t,p = scipy.stats.ttest_ind(a=df_pre[c].values,b=df_post[c].values, nan_policy='omit')\n",
    "        row=pd.DataFrame.from_dict({'var': [c],'effect':[t],'pval':[p],'stat':['ttest']})\n",
    "        if p < 0.05:\n",
    "            ax = sns.boxplot(data=df_meta, x='Timepoints', y=c, orient='v')\n",
    "            sns.swarmplot(data=df_meta, x='Timepoints', y=c, palette='dark:grey', hue=None, orient='v')\n",
    "        \n",
    "            # ax.axes.set_title(\"Title\",fontsize=48)\n",
    "            ax.set_ylabel(c,fontsize=16)\n",
    "            ax.set_xlabel('Timepoints',fontsize=16)                \n",
    "            ax.tick_params(labelsize=16)\n",
    "            sns.despine()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(path + 'outputs/' + job + '/tt_' + c  + '.pdf')\n",
    "            plt.close()            \n",
    "        row=pd.DataFrame.from_dict({'var': [c],'effect':[t],'pval':[p],'stat':['ttest']})\n",
    "        df_results = pd.concat([df_results, row])\n",
    "\n",
    "    # unpaired and then paired\n",
    "    df_pre = df_meta[df_meta['Timepoints'] == 'pre']\n",
    "    df_post = df_meta[df_meta['Timepoints'] == 'post']\n",
    "    for c in cont:\n",
    "        W,p = scipy.stats.wilcoxon(x=df_pre[c].values,y=df_post[c].values, nan_policy='omit')\n",
    "        row=pd.DataFrame.from_dict({'var': [c],'effect':[W],'pval':[p],'stat':['WSR']})\n",
    "        if p < 0.05:\n",
    "            ax = sns.boxplot(data=df_meta, x='Timepoints', y=c, orient='v')\n",
    "            sns.swarmplot(data=df_meta, x='Timepoints', y=c, palette='dark:grey', hue=None, orient='v')\n",
    "        \n",
    "            # ax.axes.set_title(\"Title\",fontsize=48)\n",
    "            ax.set_ylabel(c,fontsize=16)\n",
    "            ax.set_xlabel('Timepoints',fontsize=16)                \n",
    "            ax.tick_params(labelsize=16)\n",
    "            sns.despine()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(path + 'outputs/' + job + '/wsr_' + c  + '.pdf')\n",
    "            plt.close()            \n",
    "        row=pd.DataFrame.from_dict({'var': [c],'effect':[W],'pval':[p],'stat':['WSR']})\n",
    "        df_results = pd.concat([df_results, row])\n",
    "\n",
    "    df_pre = df_meta[df_meta['Timepoints'] == 'pre']\n",
    "    df_post = df_meta[df_meta['Timepoints'] == 'post']\n",
    "    for c in cont:\n",
    "        t,p = scipy.stats.ttest_rel(a=df_pre[c].values,b=df_post[c].values, nan_policy='omit')\n",
    "        row=pd.DataFrame.from_dict({'var': [c],'effect':[W],'pval':[p],'stat':['pairedt']})\n",
    "        if p < 0.05:\n",
    "            ax = sns.boxplot(data=df_meta, x='Timepoints', y=c, orient='v')\n",
    "            sns.swarmplot(data=df_meta, x='Timepoints', y=c, palette='dark:grey', hue=None, orient='v')\n",
    "        \n",
    "            # ax.axes.set_title(\"Title\",fontsize=48)\n",
    "            ax.set_ylabel(c,fontsize=16)\n",
    "            ax.set_xlabel('Timepoints',fontsize=16)                \n",
    "            ax.tick_params(labelsize=16)\n",
    "            sns.despine()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(path + 'outputs/' + job + '/pairedt_' + c  + '.pdf')\n",
    "            plt.close()          \n",
    "        row=pd.DataFrame.from_dict({'var': [c],'effect':[t],'pval':[p],'stat':['pairedt']})\n",
    "        df_results = pd.concat([df_results, row])\n",
    "\n",
    "    df_results.to_csv(path + 'outputs/' + job + '/outcome_testing.tsv', sep='\\t')\n",
    "df_results.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75a1b172-db26-452f-b13e-a671b23d4135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Timepoints</th>\n",
       "      <th>Study_ID</th>\n",
       "      <th>Run_ID_Stool</th>\n",
       "      <th>Run_ID_Saliva</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>...</th>\n",
       "      <th>broccoli</th>\n",
       "      <th>Garbanzo_beans</th>\n",
       "      <th>pork</th>\n",
       "      <th>beef</th>\n",
       "      <th>burger</th>\n",
       "      <th>Total_omega3</th>\n",
       "      <th>Adherence_omega3</th>\n",
       "      <th>Total_omega6</th>\n",
       "      <th>Adherence_omega6</th>\n",
       "      <th>Total_o3_o6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>VAOAD009</td>\n",
       "      <td>0</td>\n",
       "      <td>VAOAD009_0</td>\n",
       "      <td>VAOAD-009.pre.stool</td>\n",
       "      <td>VAOAD-009.pre.saliva</td>\n",
       "      <td>d-15/d0</td>\n",
       "      <td>M</td>\n",
       "      <td>71</td>\n",
       "      <td>189.0</td>\n",
       "      <td>130.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderate adherence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Low adherence</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>VAOAD009</td>\n",
       "      <td>1m</td>\n",
       "      <td>VAOAD009_1m</td>\n",
       "      <td>VAOAD-009.post.stool</td>\n",
       "      <td>VAOAD-009.post.saliva</td>\n",
       "      <td>4W</td>\n",
       "      <td>M</td>\n",
       "      <td>71</td>\n",
       "      <td>189.0</td>\n",
       "      <td>130.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.8</td>\n",
       "      <td>Moderate adherence</td>\n",
       "      <td>89.6</td>\n",
       "      <td>Low adherence</td>\n",
       "      <td>179.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>VAOAD014</td>\n",
       "      <td>0</td>\n",
       "      <td>VAOAD014_0</td>\n",
       "      <td>VAOAD-014.pre.stool</td>\n",
       "      <td>VAOAD-014.pre.saliva</td>\n",
       "      <td>d-15/d0</td>\n",
       "      <td>M</td>\n",
       "      <td>76</td>\n",
       "      <td>169.0</td>\n",
       "      <td>75.055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Low adherence</td>\n",
       "      <td>47.6</td>\n",
       "      <td>Low adherence</td>\n",
       "      <td>66.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>VAOAD014</td>\n",
       "      <td>1m</td>\n",
       "      <td>VAOAD014_1m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4W</td>\n",
       "      <td>M</td>\n",
       "      <td>76</td>\n",
       "      <td>169.0</td>\n",
       "      <td>73.500</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Low adherence</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Low adherence</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID Timepoints     Study_ID          Run_ID_Stool  \\\n",
       "32   VAOAD009          0   VAOAD009_0   VAOAD-009.pre.stool   \n",
       "33   VAOAD009        1m   VAOAD009_1m  VAOAD-009.post.stool   \n",
       "40   VAOAD014          0   VAOAD014_0   VAOAD-014.pre.stool   \n",
       "41   VAOAD014        1m   VAOAD014_1m                   NaN   \n",
       "\n",
       "            Run_ID_Saliva    Visit Sex  Age  Height   Weight  ...  broccoli  \\\n",
       "32   VAOAD-009.pre.saliva  d-15/d0   M   71   189.0  130.500  ...       0.0   \n",
       "33  VAOAD-009.post.saliva       4W   M   71   189.0  130.000  ...       0.0   \n",
       "40   VAOAD-014.pre.saliva  d-15/d0   M   76   169.0   75.055  ...       0.0   \n",
       "41                    NaN       4W   M   76   169.0   73.500  ...       4.0   \n",
       "\n",
       "   Garbanzo_beans  pork beef burger Total_omega3    Adherence_omega3  \\\n",
       "32            0.0   0.0  0.0    0.0          NaN  Moderate adherence   \n",
       "33            0.0   0.0  0.0    0.0         79.8  Moderate adherence   \n",
       "40            0.0  39.2  0.0    0.0         14.0       Low adherence   \n",
       "41            0.0  14.0  2.0    0.0         22.0       Low adherence   \n",
       "\n",
       "    Total_omega6  Adherence_omega6  Total_o3_o6  \n",
       "32           NaN     Low adherence          0.0  \n",
       "33          89.6     Low adherence        179.4  \n",
       "40          47.6     Low adherence         66.6  \n",
       "41          68.0     Low adherence        105.0  \n",
       "\n",
       "[4 rows x 170 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are only 4 samples w low adh so probably just drop from all analysis, too small to use as a control group\n",
    "df_meta = pd.read_csv(path + 'inputs/Metadata_OA.csv')\n",
    "# df = df_meta[df_meta['Adherece_antiinflam'].isnull()]\n",
    "# df = df_meta[df_meta['Adherece_antiinflam'] != 'Low adherence']\n",
    "df = df_meta[df_meta['Adherece_antiinflam'] == 'Low adherence']\n",
    "# df['Patient_ID'].unique()\n",
    "# df_meta\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "298b4824-3c24-485e-8705-5daf4a85d6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unweighted_Unifrac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OAD001</th>\n",
       "      <td>0.6598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OAD003</th>\n",
       "      <td>0.2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OAD004</th>\n",
       "      <td>0.4327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OAD005</th>\n",
       "      <td>0.3237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OAD006</th>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unweighted_Unifrac\n",
       "OAD001              0.6598\n",
       "OAD003              0.2810\n",
       "OAD004              0.4327\n",
       "OAD005              0.3237\n",
       "OAD006              0.1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "# Hypothesis 2: There will be an association between oral and gut microbiome and pain outcomes\n",
    "###\n",
    "# construct alpha, beta and paired alpha dataframes\n",
    "g_to_dfd = {}\n",
    "g_test = ['stool','saliva_adh', 'stool_adh', 'saliva']\n",
    "\n",
    "for g in g_test:\n",
    "    # maps diversity type to dataframe\n",
    "    g_to_dfd[g] = {}\n",
    "\n",
    "    # get alpha diversities\n",
    "    df_alpha = pd.read_csv(path + 'outputs/Qiime2_' + g + '/metadata.tsv', sep='\\t', index_col=0)\n",
    "    df_alpha = df_alpha.drop('#q2:types')\n",
    "    df_alpha['SubjectID'] = df_alpha['Patient_ID'] + df_alpha['Study_ID']\n",
    "    df_alpha = df_alpha[['SubjectID', 'Timepoints', 'shannon_entropy']]\n",
    "    g_to_dfd[g]['alpha'] = df_alpha\n",
    "\n",
    "    # get paired alpha div, first drop unpaired samples\n",
    "    s_remove = []\n",
    "    for s in list(df_alpha['SubjectID'].values):\n",
    "        if len(df_alpha[df_alpha['SubjectID'] == s]) != 2:\n",
    "            s_remove.append(s)\n",
    "    df_alpha = df_alpha.loc[~df_alpha['SubjectID'].isin(s_remove),:] # careful not to use ([s_remove])\n",
    "    \n",
    "    # set vars\n",
    "    alpha_metric = 'shannon_entropy'\n",
    "    group_var = 'Timepoints'\n",
    "    pair_var = 'SubjectID'\n",
    "    groups = ['pre','post']\n",
    "    \n",
    "    # get paired per indiv pair\n",
    "    pair_to_diff = {}\n",
    "    for p in list(df_alpha[pair_var].values):\n",
    "        df = df_alpha[df_alpha[pair_var] == p]\n",
    "        alpha_0 = float(df[df[group_var] == groups[0]][alpha_metric].values)\n",
    "        alpha_1 = float(df[df[group_var] == groups[1]][alpha_metric].values)\n",
    "        pair_to_diff[p] = alpha_1 - alpha_0\n",
    "    \n",
    "    df_paired_alpha = pd.DataFrame.from_dict(pair_to_diff, orient='index', columns=[alpha_metric + '_diff'])\n",
    "    g_to_dfd[g]['paired_alpha'] = df_paired_alpha\n",
    "\n",
    "    # get beta div\n",
    "    df_beta = pd.read_csv(path + 'outputs/Qiime2_' + g + '/core_metrics_results/distance-matrix.tsv',\n",
    "                              sep='\\t', index_col=0)\n",
    "        \n",
    "    # grab twin to pair dict\n",
    "    pair_to_ids = {}\n",
    "    for p in list(df_alpha[pair_var].values):\n",
    "        df = df_alpha[df_alpha[pair_var] == p]\n",
    "        id_0 = str(df[df[group_var] == groups[0]].index.values[0])\n",
    "        id_1 = str(df[df[group_var] == groups[1]].index.values[0])\n",
    "        pair_to_ids[p] = (id_0, id_1)\n",
    "    \n",
    "    # get distances for each twin pair per beta div matrix    \n",
    "    pair_to_dist = {}\n",
    "    for p in list(df_alpha[pair_var].values):\n",
    "        id_0, id_1 = pair_to_ids[p]\n",
    "        pair_to_dist[p] = df_beta.loc[id_0, id_1]\n",
    "    \n",
    "    df_paired_beta = pd.DataFrame.from_dict(pair_to_dist, orient='index', columns=['Unweighted_Unifrac'])\n",
    "    g_to_dfd[g]['paired_beta'] = df_paired_beta\n",
    "\n",
    "\n",
    "# compute paired differences in pain\n",
    "        # compute the paired differences\n",
    "\n",
    "\n",
    "g_to_dfd['stool']['paired_beta'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d4f38ff-41d6-4f31-94ab-69879de56109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>div</th>\n",
       "      <th>outcome</th>\n",
       "      <th>statistic</th>\n",
       "      <th>test_stat</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stool</td>\n",
       "      <td>alpha</td>\n",
       "      <td>WOMAC_pain</td>\n",
       "      <td>tt</td>\n",
       "      <td>2.182980</td>\n",
       "      <td>0.046561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>metadata</td>\n",
       "      <td>Adherece_antiinflam</td>\n",
       "      <td>WOMAC_activity</td>\n",
       "      <td>chisq</td>\n",
       "      <td>17.206778</td>\n",
       "      <td>0.008553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>metadata</td>\n",
       "      <td>Adherece_antiinflam</td>\n",
       "      <td>WOMAC_total</td>\n",
       "      <td>chisq</td>\n",
       "      <td>17.635958</td>\n",
       "      <td>0.007209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>metadata</td>\n",
       "      <td>Adherece_antiinflam</td>\n",
       "      <td>CES_D</td>\n",
       "      <td>chisq</td>\n",
       "      <td>12.705628</td>\n",
       "      <td>0.047956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>metadata</td>\n",
       "      <td>Adherece_antiinflam</td>\n",
       "      <td>Helplesness</td>\n",
       "      <td>chisq</td>\n",
       "      <td>13.621090</td>\n",
       "      <td>0.034167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>stool</td>\n",
       "      <td>alpha</td>\n",
       "      <td>PASE_walk</td>\n",
       "      <td>mwu</td>\n",
       "      <td>-0.324777</td>\n",
       "      <td>0.041176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>stool</td>\n",
       "      <td>alpha</td>\n",
       "      <td>PASE_walk</td>\n",
       "      <td>tt</td>\n",
       "      <td>2.424221</td>\n",
       "      <td>0.020809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>metadata</td>\n",
       "      <td>Adherece_antiinflam</td>\n",
       "      <td>PASE_light</td>\n",
       "      <td>chisq</td>\n",
       "      <td>10.145400</td>\n",
       "      <td>0.006265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>metadata</td>\n",
       "      <td>Adherece_antiinflam</td>\n",
       "      <td>BMI</td>\n",
       "      <td>chisq</td>\n",
       "      <td>15.544444</td>\n",
       "      <td>0.016420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>metadata</td>\n",
       "      <td>Adherece_antiinflam</td>\n",
       "      <td>PASE_light</td>\n",
       "      <td>chisq</td>\n",
       "      <td>4.765160</td>\n",
       "      <td>0.029041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>metadata</td>\n",
       "      <td>Adherece_antiinflam</td>\n",
       "      <td>BMI</td>\n",
       "      <td>chisq</td>\n",
       "      <td>10.927949</td>\n",
       "      <td>0.012122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>stool_adh</td>\n",
       "      <td>alpha</td>\n",
       "      <td>PASE_walk</td>\n",
       "      <td>tt</td>\n",
       "      <td>2.438537</td>\n",
       "      <td>0.021605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>metadata</td>\n",
       "      <td>Adherece_antiinflam</td>\n",
       "      <td>PASE_light</td>\n",
       "      <td>chisq</td>\n",
       "      <td>4.765160</td>\n",
       "      <td>0.029041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>metadata</td>\n",
       "      <td>Adherece_antiinflam</td>\n",
       "      <td>BMI</td>\n",
       "      <td>chisq</td>\n",
       "      <td>10.927949</td>\n",
       "      <td>0.012122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>metadata</td>\n",
       "      <td>Adherece_antiinflam</td>\n",
       "      <td>WOMAC_activity</td>\n",
       "      <td>chisq</td>\n",
       "      <td>17.206778</td>\n",
       "      <td>0.008553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>metadata</td>\n",
       "      <td>Adherece_antiinflam</td>\n",
       "      <td>WOMAC_total</td>\n",
       "      <td>chisq</td>\n",
       "      <td>17.635958</td>\n",
       "      <td>0.007209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>metadata</td>\n",
       "      <td>Adherece_antiinflam</td>\n",
       "      <td>CES_D</td>\n",
       "      <td>chisq</td>\n",
       "      <td>12.705628</td>\n",
       "      <td>0.047956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>metadata</td>\n",
       "      <td>Adherece_antiinflam</td>\n",
       "      <td>Helplesness</td>\n",
       "      <td>chisq</td>\n",
       "      <td>13.621090</td>\n",
       "      <td>0.034167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>metadata</td>\n",
       "      <td>Adherece_antiinflam</td>\n",
       "      <td>PASE_light</td>\n",
       "      <td>chisq</td>\n",
       "      <td>10.145400</td>\n",
       "      <td>0.006265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>metadata</td>\n",
       "      <td>Adherece_antiinflam</td>\n",
       "      <td>BMI</td>\n",
       "      <td>chisq</td>\n",
       "      <td>15.544444</td>\n",
       "      <td>0.016420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         group                  div         outcome statistic  test_stat  \\\n",
       "8        stool                alpha      WOMAC_pain        tt   2.182980   \n",
       "12    metadata  Adherece_antiinflam  WOMAC_activity     chisq  17.206778   \n",
       "15    metadata  Adherece_antiinflam     WOMAC_total     chisq  17.635958   \n",
       "21    metadata  Adherece_antiinflam           CES_D     chisq  12.705628   \n",
       "24    metadata  Adherece_antiinflam     Helplesness     chisq  13.621090   \n",
       "40       stool                alpha       PASE_walk       mwu  -0.324777   \n",
       "41       stool                alpha       PASE_walk        tt   2.424221   \n",
       "42    metadata  Adherece_antiinflam      PASE_light     chisq  10.145400   \n",
       "45    metadata  Adherece_antiinflam             BMI     chisq  15.544444   \n",
       "90    metadata  Adherece_antiinflam      PASE_light     chisq   4.765160   \n",
       "93    metadata  Adherece_antiinflam             BMI     chisq  10.927949   \n",
       "137  stool_adh                alpha       PASE_walk        tt   2.438537   \n",
       "138   metadata  Adherece_antiinflam      PASE_light     chisq   4.765160   \n",
       "141   metadata  Adherece_antiinflam             BMI     chisq  10.927949   \n",
       "156   metadata  Adherece_antiinflam  WOMAC_activity     chisq  17.206778   \n",
       "159   metadata  Adherece_antiinflam     WOMAC_total     chisq  17.635958   \n",
       "165   metadata  Adherece_antiinflam           CES_D     chisq  12.705628   \n",
       "168   metadata  Adherece_antiinflam     Helplesness     chisq  13.621090   \n",
       "186   metadata  Adherece_antiinflam      PASE_light     chisq  10.145400   \n",
       "189   metadata  Adherece_antiinflam             BMI     chisq  15.544444   \n",
       "\n",
       "         pval  \n",
       "8    0.046561  \n",
       "12   0.008553  \n",
       "15   0.007209  \n",
       "21   0.047956  \n",
       "24   0.034167  \n",
       "40   0.041176  \n",
       "41   0.020809  \n",
       "42   0.006265  \n",
       "45   0.016420  \n",
       "90   0.029041  \n",
       "93   0.012122  \n",
       "137  0.021605  \n",
       "138  0.029041  \n",
       "141  0.012122  \n",
       "156  0.008553  \n",
       "159  0.007209  \n",
       "165  0.047956  \n",
       "168  0.034167  \n",
       "186  0.006265  \n",
       "189  0.016420  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing for each sample type for (1) all and (2) high adh only\n",
    "# (A) Chisq of quartiles with adherence \n",
    "# (B) MWU/TT unpaired of outcomes against distance\n",
    "\n",
    "def chisq_of_df_cols(df, c1, c2):\n",
    "    groupsizes = df.groupby([c1, c2]).size()\n",
    "    ctsum = groupsizes.unstack(c1)\n",
    "    # fillna(0) is necessary to remove any NAs which will cause exceptions\n",
    "    return(scipy.stats.chi2_contingency(ctsum.fillna(0)))\n",
    "\n",
    "d_to_metric = {\n",
    "    'alpha': 'shannon_entropy',\n",
    "}\n",
    "group_var = 'Adherece_antiinflam'\n",
    "\n",
    "dfd_to_merge = {}\n",
    "g_test = ['stool','saliva_adh', 'stool_adh', 'saliva']\n",
    "\n",
    "for g in g_test:\n",
    "    dfd_to_merge[g] = {}\n",
    "\n",
    "gs = []\n",
    "ds = []\n",
    "os = []\n",
    "stats = []\n",
    "ts = []\n",
    "ps = []\n",
    "\n",
    "arr = [gs,ds,os,stats,ts,ps]\n",
    "\n",
    "def append_results(arr, val):\n",
    "    for a,v in zip(arr,val):\n",
    "        a.append(v)\n",
    "    return arr\n",
    "\n",
    "# for each sample type, grab relevant mapping file\n",
    "# g_test = saliva, saliva_adh, stool, etc.\n",
    "for g in g_test:\n",
    "    for d in d_to_metric:\n",
    "        # grab relevant diversity df\n",
    "        df_div = g_to_dfd[g][d]\n",
    "\n",
    "        if d == 'alpha':\n",
    "            # df_div = df_div[df_div['Timepoints'] == 'pre']\n",
    "            # df_div = df_div.set_index('SubjectID').drop('Timepoints',axis=1)\n",
    "            # df_div = df_div.set_index('SubjectID').drop('Timepoints',axis=1)\n",
    "            df_div['shannon_entropy'] = df_div['shannon_entropy'].astype(float)\n",
    "\n",
    "        # merge with df of metadata var        \n",
    "        # grab relevant sample IDs\n",
    "        # g = saliva_adh\n",
    "        idx = 'Run_ID_' + g.split('_')[0].capitalize()\n",
    "        df_meta_sub = df_meta.dropna(subset=idx)\n",
    "        df_meta_sub = df_meta_sub.set_index(idx)\n",
    "        df_merge = pd.concat([df_meta_sub,df_div],axis=1)\n",
    "\n",
    "        # subset on adh only\n",
    "        if g.split('_')[-1] == 'adh':\n",
    "            df_merge = df_merge[df_merge[group_var].isin(['Moderate adherence', 'High adherence'])]\n",
    "\n",
    "        # test association of div with outcomes\n",
    "        for o in outcomes:            \n",
    "            if o in 'PASE_light' or o in 'PASE_walk' or o in 'Magnification': # only 2\n",
    "                df_merge[o + '_quartiles'] = np.where(df_merge[o]==0, 'bottom', 'top')\n",
    "            #elif o in 'Magnification': # only 3 \n",
    "            #    df_merge[o + '_quartiles'] = pd.qcut(df_merge[o].values, 3, labels = ['top','mid','bottom'])#, duplicates='drop')  \n",
    "            else:\n",
    "                df_merge[o + '_quartiles'] = pd.qcut(df_merge[o].values, 4, labels = ['top','midtop','midbot','bottom'])#, duplicates='drop')  \n",
    "                \n",
    "            # test association of adherence with pain outcomes\n",
    "            div_metric = d_to_metric[d]\n",
    "            x,p,dof,ef = chisq_of_df_cols(df_merge, group_var, o + '_quartiles')\n",
    "            arr = append_results(arr, ['metadata',group_var,o,'chisq',x,p])\n",
    "            \n",
    "            ax = sns.boxplot(data=df_merge, x=o + '_quartiles', y=div_metric)\n",
    "            sns.swarmplot(data=df_merge, x=o + '_quartiles', y=div_metric, palette='dark:grey')\n",
    "            sns.despine()\n",
    "        \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(path + 'outputs/Qiime2_' + g + '/quartiles_nondiff_' + o + '_' + d + '.pdf')\n",
    "            plt.close()          \n",
    "        \n",
    "            u, p = scipy.stats.mannwhitneyu(df_merge[df_merge[o + '_quartiles'] == 'top'][div_metric].values, \n",
    "                                            df_merge[df_merge[o + '_quartiles'] == 'bottom'][div_metric].values, \n",
    "                                            nan_policy='omit')\n",
    "\n",
    "            arr = append_results(arr, [g,d,o,'mwu',t,p])\n",
    "\n",
    "            t, p = scipy.stats.ttest_ind(df_merge[df_merge[o + '_quartiles'] == 'top'][div_metric].values, \n",
    "                                            df_merge[df_merge[o + '_quartiles'] == 'bottom'][div_metric].values, \n",
    "                                            nan_policy='omit')\n",
    "\n",
    "            arr = append_results(arr, [g,d,o,'tt',t,p])\n",
    "\n",
    "        # save results\n",
    "        dfd_to_merge[g][d] = df_merge\n",
    "\n",
    "        # export to Q2\n",
    "        # df_q2_type = df_merge.set_index(['Together'])\n",
    "        df_q2_type = df_merge.copy()\n",
    "        q2_row = pd.Series(data=['categorical' for i in range(len(df_merge.columns))], \n",
    "                           index=list(df_merge.columns.values), dtype=str, name='#q2:types')\n",
    "        df_q2_type = pd.concat([q2_row.to_frame().T, df_q2_type])\n",
    "        df_q2_type.index.name = '#SampleID'\n",
    "        df_q2_type.index = df_q2_type.index.map(lambda x: x.split('.guma')[0])\n",
    "        df_q2_type.to_csv(path + 'inputs/qiime_mapping_file_' + d + '_' + g + 'aggregate_outcomes.tsv', sep='\\t')\n",
    "\n",
    "df_results = pd.DataFrame.from_dict({\n",
    "    'group': gs,\n",
    "    'div': ds,\n",
    "    'outcome': os,\n",
    "    'statistic': stats,\n",
    "    'test_stat': ts,\n",
    "    'pval': ps\n",
    "})\n",
    "df_results.to_csv(path + 'outputs/df_results_aggregate.tsv', sep='\\t')\n",
    "\n",
    "# df_results.head()\n",
    "df_results[df_results['pval'] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22f26972-623f-459c-93fd-d37eb65d17eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>div</th>\n",
       "      <th>outcome</th>\n",
       "      <th>statistic</th>\n",
       "      <th>test_stat</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stool</td>\n",
       "      <td>alpha</td>\n",
       "      <td>VAS_Pt_nondiff</td>\n",
       "      <td>pearson</td>\n",
       "      <td>-0.633181</td>\n",
       "      <td>0.015068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stool</td>\n",
       "      <td>alpha</td>\n",
       "      <td>VAS_Pt_nondiff</td>\n",
       "      <td>spearman</td>\n",
       "      <td>-0.742293</td>\n",
       "      <td>0.002363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>stool</td>\n",
       "      <td>paired_alpha</td>\n",
       "      <td>WOMAC_activity</td>\n",
       "      <td>tt</td>\n",
       "      <td>3.013993</td>\n",
       "      <td>0.023579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>stool</td>\n",
       "      <td>paired_alpha</td>\n",
       "      <td>WOMAC_total</td>\n",
       "      <td>tt</td>\n",
       "      <td>3.793806</td>\n",
       "      <td>0.012709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>stool_adh</td>\n",
       "      <td>alpha</td>\n",
       "      <td>VAS_Pt_nondiff</td>\n",
       "      <td>pearson</td>\n",
       "      <td>-0.756077</td>\n",
       "      <td>0.002787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>stool_adh</td>\n",
       "      <td>alpha</td>\n",
       "      <td>VAS_Pt_nondiff</td>\n",
       "      <td>spearman</td>\n",
       "      <td>-0.818185</td>\n",
       "      <td>0.000630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>stool_adh</td>\n",
       "      <td>alpha</td>\n",
       "      <td>VAS_Pt</td>\n",
       "      <td>pearson</td>\n",
       "      <td>0.639497</td>\n",
       "      <td>0.018595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>stool_adh</td>\n",
       "      <td>alpha</td>\n",
       "      <td>VAS_Pt</td>\n",
       "      <td>spearman</td>\n",
       "      <td>0.675824</td>\n",
       "      <td>0.011225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>stool_adh</td>\n",
       "      <td>alpha</td>\n",
       "      <td>Pain_DETECT_nondiff</td>\n",
       "      <td>pearson</td>\n",
       "      <td>0.554886</td>\n",
       "      <td>0.049034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>stool_adh</td>\n",
       "      <td>alpha</td>\n",
       "      <td>Pain_DETECT_nondiff</td>\n",
       "      <td>spearman</td>\n",
       "      <td>0.633611</td>\n",
       "      <td>0.020065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>stool_adh</td>\n",
       "      <td>paired_alpha</td>\n",
       "      <td>VAS_Pt</td>\n",
       "      <td>tt</td>\n",
       "      <td>3.058171</td>\n",
       "      <td>0.028161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>stool_adh</td>\n",
       "      <td>paired_alpha</td>\n",
       "      <td>VAS_Pt</td>\n",
       "      <td>spearman</td>\n",
       "      <td>-0.593407</td>\n",
       "      <td>0.032524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>stool_adh</td>\n",
       "      <td>paired_alpha</td>\n",
       "      <td>VAS_overall</td>\n",
       "      <td>tt</td>\n",
       "      <td>3.164672</td>\n",
       "      <td>0.024964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>stool_adh</td>\n",
       "      <td>paired_alpha</td>\n",
       "      <td>VAS_overall</td>\n",
       "      <td>pearson</td>\n",
       "      <td>-0.561268</td>\n",
       "      <td>0.045954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>stool_adh</td>\n",
       "      <td>paired_alpha</td>\n",
       "      <td>WOMAC_pain</td>\n",
       "      <td>tt</td>\n",
       "      <td>3.960201</td>\n",
       "      <td>0.016675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>stool_adh</td>\n",
       "      <td>paired_alpha</td>\n",
       "      <td>WOMAC_activity</td>\n",
       "      <td>tt</td>\n",
       "      <td>3.052571</td>\n",
       "      <td>0.022438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>stool_adh</td>\n",
       "      <td>paired_alpha</td>\n",
       "      <td>WOMAC_total</td>\n",
       "      <td>tt</td>\n",
       "      <td>3.761469</td>\n",
       "      <td>0.013138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>stool_adh</td>\n",
       "      <td>paired_alpha</td>\n",
       "      <td>BMI</td>\n",
       "      <td>spearman</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.019942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>saliva</td>\n",
       "      <td>alpha</td>\n",
       "      <td>WOMAC_total</td>\n",
       "      <td>tt</td>\n",
       "      <td>2.953736</td>\n",
       "      <td>0.031748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>saliva</td>\n",
       "      <td>paired_beta</td>\n",
       "      <td>PASE_walk</td>\n",
       "      <td>mwu</td>\n",
       "      <td>0.243425</td>\n",
       "      <td>0.000666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>saliva</td>\n",
       "      <td>paired_beta</td>\n",
       "      <td>PASE_walk</td>\n",
       "      <td>tt</td>\n",
       "      <td>4.719238</td>\n",
       "      <td>0.000498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>saliva</td>\n",
       "      <td>paired_beta</td>\n",
       "      <td>PASE_light</td>\n",
       "      <td>tt</td>\n",
       "      <td>2.802932</td>\n",
       "      <td>0.015957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>saliva_adh</td>\n",
       "      <td>alpha</td>\n",
       "      <td>WOMAC_total</td>\n",
       "      <td>tt</td>\n",
       "      <td>3.044235</td>\n",
       "      <td>0.028612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>saliva_adh</td>\n",
       "      <td>alpha</td>\n",
       "      <td>Helplesness</td>\n",
       "      <td>tt</td>\n",
       "      <td>3.255085</td>\n",
       "      <td>0.022568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>saliva_adh</td>\n",
       "      <td>paired_beta</td>\n",
       "      <td>PASE_walk</td>\n",
       "      <td>mwu</td>\n",
       "      <td>-0.112894</td>\n",
       "      <td>0.001166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>saliva_adh</td>\n",
       "      <td>paired_beta</td>\n",
       "      <td>PASE_walk</td>\n",
       "      <td>tt</td>\n",
       "      <td>4.667067</td>\n",
       "      <td>0.000686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>saliva_adh</td>\n",
       "      <td>paired_beta</td>\n",
       "      <td>PASE_light</td>\n",
       "      <td>tt</td>\n",
       "      <td>2.614012</td>\n",
       "      <td>0.024085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           group           div              outcome statistic  test_stat  \\\n",
       "4          stool         alpha       VAS_Pt_nondiff   pearson  -0.633181   \n",
       "5          stool         alpha       VAS_Pt_nondiff  spearman  -0.742293   \n",
       "136        stool  paired_alpha       WOMAC_activity        tt   3.013993   \n",
       "141        stool  paired_alpha          WOMAC_total        tt   3.793806   \n",
       "280    stool_adh         alpha       VAS_Pt_nondiff   pearson  -0.756077   \n",
       "281    stool_adh         alpha       VAS_Pt_nondiff  spearman  -0.818185   \n",
       "282    stool_adh         alpha               VAS_Pt   pearson   0.639497   \n",
       "283    stool_adh         alpha               VAS_Pt  spearman   0.675824   \n",
       "322    stool_adh         alpha  Pain_DETECT_nondiff   pearson   0.554886   \n",
       "323    stool_adh         alpha  Pain_DETECT_nondiff  spearman   0.633611   \n",
       "393    stool_adh  paired_alpha               VAS_Pt        tt   3.058171   \n",
       "395    stool_adh  paired_alpha               VAS_Pt  spearman  -0.593407   \n",
       "398    stool_adh  paired_alpha          VAS_overall        tt   3.164672   \n",
       "399    stool_adh  paired_alpha          VAS_overall   pearson  -0.561268   \n",
       "403    stool_adh  paired_alpha           WOMAC_pain        tt   3.960201   \n",
       "413    stool_adh  paired_alpha       WOMAC_activity        tt   3.052571   \n",
       "418    stool_adh  paired_alpha          WOMAC_total        tt   3.761469   \n",
       "470    stool_adh  paired_alpha                  BMI  spearman  -0.750000   \n",
       "591       saliva         alpha          WOMAC_total        tt   2.953736   \n",
       "814       saliva   paired_beta            PASE_walk       mwu   0.243425   \n",
       "815       saliva   paired_beta            PASE_walk        tt   4.719238   \n",
       "820       saliva   paired_beta           PASE_light        tt   2.802932   \n",
       "867   saliva_adh         alpha          WOMAC_total        tt   3.044235   \n",
       "888   saliva_adh         alpha          Helplesness        tt   3.255085   \n",
       "1092  saliva_adh   paired_beta            PASE_walk       mwu  -0.112894   \n",
       "1093  saliva_adh   paired_beta            PASE_walk        tt   4.667067   \n",
       "1098  saliva_adh   paired_beta           PASE_light        tt   2.614012   \n",
       "\n",
       "          pval  \n",
       "4     0.015068  \n",
       "5     0.002363  \n",
       "136   0.023579  \n",
       "141   0.012709  \n",
       "280   0.002787  \n",
       "281   0.000630  \n",
       "282   0.018595  \n",
       "283   0.011225  \n",
       "322   0.049034  \n",
       "323   0.020065  \n",
       "393   0.028161  \n",
       "395   0.032524  \n",
       "398   0.024964  \n",
       "399   0.045954  \n",
       "403   0.016675  \n",
       "413   0.022438  \n",
       "418   0.013138  \n",
       "470   0.019942  \n",
       "591   0.031748  \n",
       "814   0.000666  \n",
       "815   0.000498  \n",
       "820   0.015957  \n",
       "867   0.028612  \n",
       "888   0.022568  \n",
       "1092  0.001166  \n",
       "1093  0.000686  \n",
       "1098  0.024085  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expand previous to all data, paired and unpaired diversities\n",
    "d_to_metric = {\n",
    "    'alpha': 'shannon_entropy',\n",
    "    'paired_alpha': 'shannon_entropy_diff',\n",
    "    'paired_beta': 'Unweighted_Unifrac',\n",
    "}\n",
    "group_var = 'Adherece_antiinflam'\n",
    "\n",
    "dfd_to_merge = {}\n",
    "g_test = ['stool','stool_adh','saliva','saliva_adh']\n",
    "for g in g_test:\n",
    "    dfd_to_merge[g] = {}\n",
    "\n",
    "gs = []\n",
    "ds = []\n",
    "os = []\n",
    "stats = []\n",
    "ts = []\n",
    "ps = []\n",
    "\n",
    "arr = [gs,ds,os,stats,ts,ps]\n",
    "\n",
    "def append_results(arr, val):\n",
    "    for a,v in zip(arr,val):\n",
    "        a.append(v)\n",
    "    return arr\n",
    "\n",
    "# for each sample type, grab relevant mapping file\n",
    "# g_test = saliva, saliva_adh, stool, etc.\n",
    "for g in g_test:\n",
    "    # drop duplicates so you have sample mapping to adh\n",
    "    df_map_sub = type_to_df_map[g.split('_')[0]]\n",
    "    df_map_sub.index = df_map_sub.index.map(lambda x: x.split('.')[0].replace('-',''))\n",
    "    df_map_sub = df_map_sub.dropna(how='any',subset=group_var,axis=0)           \n",
    "    \n",
    "    # figure out which samples to keep\n",
    "    # i.e. samples that have a pre and post time point\n",
    "    keep = []\n",
    "    for i in list(df_map_sub.index.values):\n",
    "        if len(df_map_sub.loc[i,:]) == 2:\n",
    "            keep.append(i)\n",
    "\n",
    "    # get unique entires in sorted order\n",
    "    # at this point we are only concerned with differences in values, \n",
    "    # as we've dropped samples with only one endpoint val\n",
    "    save = []\n",
    "    [save.append(x) for x in keep if x not in save]\n",
    "    df_map_sub = df_map_sub.loc[save,:]\n",
    "\n",
    "    # this double populates as OAD001 is an index twice, so the diff fills to both the pre and post col\n",
    "    for o in outcomes:\n",
    "        df_map_sub[o + '_diff'] = df_map_sub[df_map_sub['Timepoint'] == 'post'][o] - df_map_sub[df_map_sub['Timepoint'] == 'pre'][o] \n",
    "\n",
    "    # here we keep only the pre, but everything is identical b/w pre and post\n",
    "    df_dropdup = df_map_sub[~df_map_sub.index.duplicated(keep='first')]\n",
    "\n",
    "    for d in d_to_metric:\n",
    "        # grab relevant diversity df\n",
    "        df_div = g_to_dfd[g][d]\n",
    "\n",
    "        # when associating alpha div vs outcomes, look at if starting adiv predicts outcome\n",
    "        if d == 'alpha':\n",
    "            df_div = df_div[df_div['Timepoints'] == 'pre']\n",
    "            df_div = df_div.set_index('SubjectID').drop('Timepoints',axis=1)\n",
    "            df_div = df_div.astype(float)\n",
    "\n",
    "        # merge with df of metadata var        \n",
    "        df_merge = pd.concat([df_dropdup,df_div],axis=1)\n",
    "\n",
    "        # drop na in barcodes if samples not sequenced both pre and post\n",
    "        df_merge = df_merge.dropna(how='any',subset='BarcodeSequence')\n",
    "\n",
    "        # build expandable arrays\n",
    "        values = list(df_merge[group_var].unique())\n",
    "        arr_list = [list(df_merge.groupby([group_var]).get_group(values[i])[d_to_metric[d]].values) for i in range(len(values))]\n",
    "    \n",
    "        # test difference of paired differences between two adherence groups (mod vs high only)\n",
    "        if len(g.split('_')) == 2:\n",
    "            s, p = scipy.stats.mannwhitneyu(arr_list[0], arr_list[1], nan_policy='omit')\n",
    "            arr = append_results(arr, [g,d,'adh','mwh',s,p])\n",
    "\n",
    "            s, p = scipy.stats.ttest_ind(arr_list[0], arr_list[1], nan_policy='omit')\n",
    "            arr = append_results(arr, [g,d,'adh','tt',s,p])\n",
    "\n",
    "        if len(g.split('_')) == 1: # tests across all 3 groups\n",
    "            s, p = scipy.stats.kruskal(*arr_list, nan_policy='omit')\n",
    "            arr = append_results(arr, [g,d,'adh','kw',s,p])\n",
    "\n",
    "            #f, p = scipy.stats.f_oneway(*arr_list, nan_policy='omit')\n",
    "            #print(f, p)\n",
    "\n",
    "        # separate plot\n",
    "        div_metric = d_to_metric[d]\n",
    "        df_merge[div_metric] = df_merge[div_metric].map(lambda x: float(x))\n",
    "        ax = sns.boxplot(data=df_merge, x=group_var, y=div_metric)\n",
    "        sns.swarmplot(data=df_merge, x=group_var, y=div_metric, palette='dark:grey')\n",
    "        sns.despine()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(path + 'outputs/Qiime2_' + g + '/' + d + '.pdf')\n",
    "        plt.close()          \n",
    "\n",
    "        # test association of div with outcomes\n",
    "        for o in outcomes:            \n",
    "            if o in 'PASE_light' or o in 'PASE_walk': # only 2\n",
    "                df_merge[o + '_quartiles'] = np.where(df_merge[o + '_diff']==0, 'bottom', 'top')\n",
    "            #elif o in 'PASE_walk': # only 3 \n",
    "            #    df_merge[o + '_quartiles'] = pd.qcut(df_merge[o + '_diff'].values, 3, labels = ['top','mid','bottom'])#, duplicates='drop')  \n",
    "            else:\n",
    "                df_merge[o + '_quartiles'] = pd.qcut(df_merge[o + '_diff'].values, 4, labels = ['top','midtop','midbot','bottom'])#, duplicates='drop')  \n",
    "                \n",
    "            # test association of adherence with pain outcomes\n",
    "            x,p,dof,ef = chisq_of_df_cols(df_merge, group_var, o + '_quartiles')\n",
    "            arr = append_results(arr, ['metadata','chisq',o,group_var,x,p])\n",
    "            \n",
    "            ax = sns.boxplot(data=df_merge, y=o + '_quartiles', x=div_metric)\n",
    "            sns.swarmplot(data=df_merge, y=o + '_quartiles', x=div_metric, palette='dark:grey')\n",
    "            sns.despine()\n",
    "        \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(path + 'outputs/Qiime2_' + g + '/quartiles_' + o + '_' + d + '.pdf')\n",
    "            plt.close()          \n",
    "\n",
    "            # MWU and ttest for quartiles\n",
    "            u, p = scipy.stats.mannwhitneyu(df_merge[df_merge[o + '_quartiles'] == 'top'][div_metric].values, \n",
    "                                            df_merge[df_merge[o + '_quartiles'] == 'bottom'][div_metric].values, \n",
    "                                            nan_policy='omit')\n",
    "\n",
    "            arr = append_results(arr, [g,d,o,'mwu',t,p])\n",
    "\n",
    "            t, p = scipy.stats.ttest_ind(df_merge[df_merge[o + '_quartiles'] == 'top'][div_metric].values, \n",
    "                                            df_merge[df_merge[o + '_quartiles'] == 'bottom'][div_metric].values, \n",
    "                                            nan_policy='omit')\n",
    "\n",
    "            arr = append_results(arr, [g,d,o,'tt',t,p])\n",
    "            \n",
    "            # correlations (get df dropping nas) for metric and div metric not doing any diffs\n",
    "            if d == 'alpha':\n",
    "                df_corr = df_merge.loc[:,[div_metric,o]].dropna(how='any',axis=0)\n",
    "                r, p = scipy.stats.pearsonr(df_corr[div_metric].values, \n",
    "                                            df_corr[o].values)\n",
    "                \n",
    "                arr = append_results(arr, [g, d, o + '_nondiff', 'pearson', r, p])\n",
    "    \n",
    "                r, p = scipy.stats.spearmanr(df_corr[div_metric].values, \n",
    "                                            df_corr[o].values)\n",
    "                arr = append_results(arr, [g, d, o + '_nondiff', 'spearman', r, p])\n",
    "                ax = sns.scatterplot(data=df_corr, x=div_metric, y=o)\n",
    "                sns.despine()\n",
    "            \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(path + 'outputs/Qiime2_' + g + '/scatter_nondiff_' + o + '_' + d + '.pdf')\n",
    "                plt.close()          \n",
    "            \n",
    "            # correlations (get df dropping nas) for metric and div metric \n",
    "            df_corr = df_merge.loc[:,[div_metric,o + '_diff']].dropna(how='any',axis=0)\n",
    "            r, p = scipy.stats.pearsonr(df_corr[div_metric].values, \n",
    "                                        df_corr[o + '_diff'].values)\n",
    "            \n",
    "            arr = append_results(arr, [g, d, o, 'pearson', r, p])\n",
    "\n",
    "            r, p = scipy.stats.spearmanr(df_corr[div_metric].values, \n",
    "                                        df_corr[o + '_diff'].values)\n",
    "            arr = append_results(arr, [g, d, o, 'spearman', r, p])\n",
    "            ax = sns.scatterplot(data=df_corr, x=div_metric, y=o+'_diff')\n",
    "            sns.despine()\n",
    "        \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(path + 'outputs/Qiime2_' + g + '/scatter_' + o + '_' + d + '.pdf')\n",
    "            plt.close()          \n",
    "\n",
    "            # do against paired outcomes\n",
    "\n",
    "        \n",
    "        # save results\n",
    "        dfd_to_merge[g][d] = df_merge\n",
    "\n",
    "        # export to Q2\n",
    "        df_q2_type = df_merge.set_index(['Together'])\n",
    "        q2_row = pd.Series(data=['categorical' for i in range(len(df_merge.columns))], \n",
    "                           index=list(df_merge.columns.values), dtype=str, name='#q2:types')\n",
    "        df_q2_type = pd.concat([q2_row.to_frame().T, df_q2_type])\n",
    "        df_q2_type.index.name = '#SampleID'\n",
    "        df_q2_type.index = df_q2_type.index.map(lambda x: x.split('.guma')[0])\n",
    "        df_q2_type.to_csv(path + 'inputs/qiime_mapping_file_' + d + '_' + g + '_outcomes.tsv', sep='\\t')\n",
    "\n",
    "df_results = pd.DataFrame.from_dict({\n",
    "    'group': gs,\n",
    "    'div': ds,\n",
    "    'outcome': os,\n",
    "    'statistic': stats,\n",
    "    'test_stat': ts,\n",
    "    'pval': ps\n",
    "})\n",
    "df_results.to_csv(path + 'outputs/df_results_diff.tsv', sep='\\t')\n",
    "\n",
    "# df_results.head()\n",
    "# the div==alpha results test whether pre-alpha div state associates with pain outcome changes (differences) quartiles\n",
    "# the div==paired_alpha and paired_beta test whether the alpha and betas change in a similar way with the pain outcome\n",
    "df_results[df_results['pval'] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bef8c05d-208b-4b13-bac7-01bf00e4e80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stool\n",
      "-1.3915055584010403 0.18742571819824966\n",
      "32.0 0.216552734375\n",
      "19.791605413728398 8.697341946647297e-09\n",
      "stool_adh\n",
      "-0.8431170083800213 0.41565264980514804\n",
      "33.0 0.414306640625\n",
      "19.758788186800356 1.3917405228254534e-08\n",
      "saliva\n",
      "-1.1344185764568935 0.27710443198722506\n",
      "36.0 0.3258056640625\n",
      "18.206265250501016 3.536855471794521e-08\n",
      "saliva_adh\n",
      "-1.3787450789345674 0.1931323321786041\n",
      "30.0 0.305419921875\n",
      "11.976305593222191 1.194161818002086e-05\n"
     ]
    }
   ],
   "source": [
    "# Alpha div paired\n",
    "# paired beta, comparing intra-indiv difference pre_post to inter pre and inter post\n",
    "\n",
    "for g in g_test: #subgroups:\n",
    "    print(g)\n",
    "    df_alpha = pd.read_csv(path + 'outputs/Qiime2_' + g + '/metadata.tsv', sep='\\t', index_col=0)\n",
    "    df_alpha = df_alpha.drop('#q2:types')\n",
    "    df_alpha['SubjectID'] = df_alpha['Patient_ID'] + df_alpha['Study_ID']\n",
    "    df_alpha = df_alpha[['SubjectID', 'Timepoints', 'shannon_entropy']]\n",
    "    \n",
    "    # drop unpaired samples\n",
    "    s_remove = []\n",
    "    for s in list(df_alpha['SubjectID'].values):\n",
    "        if len(df_alpha[df_alpha['SubjectID'] == s]) != 2:\n",
    "            s_remove.append(s)\n",
    "    df_alpha = df_alpha.loc[~df_alpha['SubjectID'].isin(s_remove),:] # careful not to use ([s_remove])\n",
    "    \n",
    "    # set vars\n",
    "    alpha_metric = 'shannon_entropy'\n",
    "    group_var = 'Timepoints'\n",
    "    pair_var = 'SubjectID'\n",
    "    groups = ['pre','post']\n",
    "    \n",
    "    # get paired per indiv pair\n",
    "    pair_to_diff = {}\n",
    "    for p in list(df_alpha[pair_var].values):\n",
    "        df = df_alpha[df_alpha[pair_var] == p]\n",
    "        alpha_0 = float(df[df[group_var] == groups[0]][alpha_metric].values)\n",
    "        alpha_1 = float(df[df[group_var] == groups[1]][alpha_metric].values)\n",
    "        pair_to_diff[p] = alpha_0 - alpha_1\n",
    "    \n",
    "    df_paired_alpha = pd.DataFrame.from_dict(pair_to_diff, orient='index', columns=[alpha_metric + '_diff'])\n",
    "    \n",
    "    # one-sided t-test, n.s.; RA-UA values \n",
    "    t, p = scipy.stats.ttest_1samp(df_paired_alpha[alpha_metric + '_diff'],popmean=0)\n",
    "    print(t, p)\n",
    "    \n",
    "    s, p = scipy.stats.wilcoxon(df_paired_alpha[alpha_metric + '_diff'])\n",
    "    print(s, p)\n",
    "    \n",
    "    # separate\n",
    "    df_alpha[alpha_metric] = df_alpha[alpha_metric].map(lambda x: float(x))\n",
    "    ax = sns.boxplot(data=df_alpha, x=group_var, y=alpha_metric)\n",
    "    sns.swarmplot(data=df_alpha, x=group_var, y=alpha_metric, palette='dark:grey')\n",
    "    sns.despine()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path + 'outputs/Qiime2_' + g + '/alpha.pdf')\n",
    "    plt.close()          \n",
    "\n",
    "    # now do beta\n",
    "    df_beta = pd.read_csv(path + 'outputs/Qiime2_' + g + '/core_metrics_results/distance-matrix.tsv',\n",
    "                          sep='\\t', index_col=0)\n",
    "    \n",
    "    # set vars\n",
    "    alpha_metric = 'shannon_entropy'\n",
    "    group_var = 'Timepoints'\n",
    "    pair_var = 'SubjectID'\n",
    "    groups = ['pre','post']\n",
    "    g0, g1 = groups[0], groups[1]\n",
    "    \n",
    "    # grab twin to pair dict\n",
    "    pair_to_ids = {}\n",
    "    for p in list(df_alpha[pair_var].values):\n",
    "        df = df_alpha[df_alpha[pair_var] == p]\n",
    "        id_0 = str(df[df[group_var] == g0].index.values[0])\n",
    "        id_1 = str(df[df[group_var] == g1].index.values[0])\n",
    "        pair_to_ids[p] = (id_0, id_1)\n",
    "    \n",
    "    # get distances for each twin pair per beta div matrix    \n",
    "    pair_to_dist = {}\n",
    "    for p in list(df_alpha[pair_var].values):\n",
    "        id_0, id_1 = pair_to_ids[p]\n",
    "        pair_to_dist[p] = df_beta.loc[id_0, id_1]\n",
    "    \n",
    "    df_paired_beta = pd.DataFrame.from_dict(pair_to_dist, orient='index', columns=['Unweighted_Unifrac'])\n",
    "    \n",
    "    # grab inter RA distances\n",
    "    # this is from unweighted_Timepoint_significance.qzv -> download as tsv\n",
    "    df_raw = pd.read_csv(path + 'outputs/Qiime2_' + g + '/raw_data.tsv', \n",
    "                         sep='\\t', index_col=0)\n",
    "    df_0 = df_raw[df_raw['Group1'] == g0]\n",
    "    df_0 = df_0[df_0['Group2'] == g0]\n",
    "    df_1 = df_raw[df_raw['Group1'] == g1]\n",
    "    df_1 = df_1[df_1['Group2'] == g1]\n",
    "    \n",
    "    # compare distances\n",
    "    inter_twin = df_paired_beta['Unweighted_Unifrac'].values\n",
    "    inter_0 = df_0['Distance'].values\n",
    "    inter_1 = df_1['Distance'].values\n",
    "    \n",
    "    u, p = scipy.stats.mannwhitneyu(inter_twin, inter_0)\n",
    "    #print(u, p)\n",
    "    \n",
    "    t, p = scipy.stats.ttest_ind(inter_twin, inter_1)\n",
    "    #print(t, p)\n",
    "    \n",
    "    t, p = scipy.stats.ttest_ind(inter_0, inter_1)\n",
    "    # print(t, p)\n",
    "    \n",
    "    f, p = scipy.stats.f_oneway(inter_0, inter_1, inter_twin)\n",
    "    print(f, p)\n",
    "    \n",
    "    category = ['intra_twin_pair']*len(inter_twin) + ['inter_' + g0 + '_only']*len(inter_0) + ['inter_' + g1 + '_only']*len(inter_1)\n",
    "    distances = list(inter_twin) + list(inter_0) + list(inter_1)\n",
    "    df_dist = pd.DataFrame(data=np.array([category,distances]).T, columns=['category','distance'])\n",
    "    df_dist['distance'] = df_dist['distance'].astype(float)\n",
    "    df_dist.to_csv(path + 'outputs/Qiime2_' + g + '/inter_intra_beta_dist.tsv',sep='\\t')\n",
    "                         \n",
    "    sns.boxplot(data=df_dist, x='category', y='distance')\n",
    "    sns.swarmplot(data=df_dist, x='category', y='distance', color='black')\n",
    "    sns.despine()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path + 'outputs/Qiime2_' + g + '/beta.pdf')\n",
    "    plt.close()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bf1fdd5-b592-4a4e-a5d4-3cefc2d28c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H_Pyridoxamine</th>\n",
       "      <th>H_Thiamine</th>\n",
       "      <th>H_Melezitose</th>\n",
       "      <th>H_Phosphocholine</th>\n",
       "      <th>H_SN_Glycero_3_Phophocholine</th>\n",
       "      <th>H_Gamma_Valerobetaine</th>\n",
       "      <th>H_N_Acetylneuraminic_acid</th>\n",
       "      <th>H_Pyridoxine</th>\n",
       "      <th>H_N_Acetylneuraminic_Acid</th>\n",
       "      <th>H_N_Acetylmuramic_Acid</th>\n",
       "      <th>...</th>\n",
       "      <th>H_Nonhydroxylated_bile_acid</th>\n",
       "      <th>H_Hydroxydodecanoic_acid</th>\n",
       "      <th>H_Omega_Hydroxydodecanoate</th>\n",
       "      <th>H_Delta_Methyldodecenoic_Acid</th>\n",
       "      <th>H_Hydroxydecanoic_acid</th>\n",
       "      <th>H_Hydroxydecanoate</th>\n",
       "      <th>H_Methylpentanoic_acid</th>\n",
       "      <th>H_Monohydroxylated_bile_acid</th>\n",
       "      <th>H_Palmitoyl_ethanolamide</th>\n",
       "      <th>H_Linoleic_Acid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Study_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VAOAD001</th>\n",
       "      <td>0.312342</td>\n",
       "      <td>-0.312477</td>\n",
       "      <td>0.119853</td>\n",
       "      <td>-0.492876</td>\n",
       "      <td>-0.671376</td>\n",
       "      <td>-0.202952</td>\n",
       "      <td>0.203945</td>\n",
       "      <td>-0.455869</td>\n",
       "      <td>0.352628</td>\n",
       "      <td>0.151464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054336</td>\n",
       "      <td>-0.330037</td>\n",
       "      <td>-0.886045</td>\n",
       "      <td>-0.314427</td>\n",
       "      <td>-0.322677</td>\n",
       "      <td>-0.650357</td>\n",
       "      <td>-0.361695</td>\n",
       "      <td>0.132794</td>\n",
       "      <td>-0.067464</td>\n",
       "      <td>-0.112641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAOAD009</th>\n",
       "      <td>0.000428</td>\n",
       "      <td>-0.481251</td>\n",
       "      <td>-0.179337</td>\n",
       "      <td>0.983217</td>\n",
       "      <td>0.167836</td>\n",
       "      <td>0.067823</td>\n",
       "      <td>0.364897</td>\n",
       "      <td>-0.371942</td>\n",
       "      <td>0.545435</td>\n",
       "      <td>-0.007664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022614</td>\n",
       "      <td>-0.334936</td>\n",
       "      <td>-0.802118</td>\n",
       "      <td>-0.929470</td>\n",
       "      <td>-0.369578</td>\n",
       "      <td>-0.566431</td>\n",
       "      <td>0.075375</td>\n",
       "      <td>-0.519189</td>\n",
       "      <td>-0.180631</td>\n",
       "      <td>-0.418351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OAD001</th>\n",
       "      <td>-0.285212</td>\n",
       "      <td>-0.556445</td>\n",
       "      <td>-0.651325</td>\n",
       "      <td>0.357509</td>\n",
       "      <td>-0.401875</td>\n",
       "      <td>-0.295787</td>\n",
       "      <td>0.137736</td>\n",
       "      <td>-0.165902</td>\n",
       "      <td>0.112170</td>\n",
       "      <td>0.096791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.923477</td>\n",
       "      <td>-0.589028</td>\n",
       "      <td>-1.535141</td>\n",
       "      <td>-0.525277</td>\n",
       "      <td>-0.278312</td>\n",
       "      <td>-0.600484</td>\n",
       "      <td>0.019657</td>\n",
       "      <td>-0.576831</td>\n",
       "      <td>-0.901479</td>\n",
       "      <td>-1.089906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAOAD004</th>\n",
       "      <td>0.140904</td>\n",
       "      <td>1.089055</td>\n",
       "      <td>-0.668077</td>\n",
       "      <td>-1.061336</td>\n",
       "      <td>-0.370602</td>\n",
       "      <td>-0.329379</td>\n",
       "      <td>-0.654931</td>\n",
       "      <td>0.142971</td>\n",
       "      <td>-1.006689</td>\n",
       "      <td>-0.100373</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.354297</td>\n",
       "      <td>0.449897</td>\n",
       "      <td>0.489189</td>\n",
       "      <td>0.413723</td>\n",
       "      <td>0.474250</td>\n",
       "      <td>0.661963</td>\n",
       "      <td>0.245553</td>\n",
       "      <td>0.279290</td>\n",
       "      <td>-0.444319</td>\n",
       "      <td>-0.912164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAOAD011</th>\n",
       "      <td>-0.346855</td>\n",
       "      <td>1.028262</td>\n",
       "      <td>-0.450323</td>\n",
       "      <td>-0.025939</td>\n",
       "      <td>-0.223029</td>\n",
       "      <td>-0.766374</td>\n",
       "      <td>-0.538410</td>\n",
       "      <td>-1.091423</td>\n",
       "      <td>-0.328522</td>\n",
       "      <td>-0.524686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.385428</td>\n",
       "      <td>0.419748</td>\n",
       "      <td>0.429119</td>\n",
       "      <td>0.333756</td>\n",
       "      <td>0.448461</td>\n",
       "      <td>0.598846</td>\n",
       "      <td>0.390035</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>-0.532141</td>\n",
       "      <td>-0.752280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          H_Pyridoxamine  H_Thiamine  H_Melezitose  H_Phosphocholine  \\\n",
       "Study_ID                                                               \n",
       "VAOAD001        0.312342   -0.312477      0.119853         -0.492876   \n",
       "VAOAD009        0.000428   -0.481251     -0.179337          0.983217   \n",
       "OAD001         -0.285212   -0.556445     -0.651325          0.357509   \n",
       "VAOAD004        0.140904    1.089055     -0.668077         -1.061336   \n",
       "VAOAD011       -0.346855    1.028262     -0.450323         -0.025939   \n",
       "\n",
       "          H_SN_Glycero_3_Phophocholine  H_Gamma_Valerobetaine  \\\n",
       "Study_ID                                                        \n",
       "VAOAD001                     -0.671376              -0.202952   \n",
       "VAOAD009                      0.167836               0.067823   \n",
       "OAD001                       -0.401875              -0.295787   \n",
       "VAOAD004                     -0.370602              -0.329379   \n",
       "VAOAD011                     -0.223029              -0.766374   \n",
       "\n",
       "          H_N_Acetylneuraminic_acid  H_Pyridoxine  H_N_Acetylneuraminic_Acid  \\\n",
       "Study_ID                                                                       \n",
       "VAOAD001                   0.203945     -0.455869                   0.352628   \n",
       "VAOAD009                   0.364897     -0.371942                   0.545435   \n",
       "OAD001                     0.137736     -0.165902                   0.112170   \n",
       "VAOAD004                  -0.654931      0.142971                  -1.006689   \n",
       "VAOAD011                  -0.538410     -1.091423                  -0.328522   \n",
       "\n",
       "          H_N_Acetylmuramic_Acid  ...  H_Nonhydroxylated_bile_acid  \\\n",
       "Study_ID                          ...                                \n",
       "VAOAD001                0.151464  ...                     0.054336   \n",
       "VAOAD009               -0.007664  ...                    -0.022614   \n",
       "OAD001                  0.096791  ...                    -0.923477   \n",
       "VAOAD004               -0.100373  ...                    -0.354297   \n",
       "VAOAD011               -0.524686  ...                    -0.385428   \n",
       "\n",
       "          H_Hydroxydodecanoic_acid  H_Omega_Hydroxydodecanoate  \\\n",
       "Study_ID                                                         \n",
       "VAOAD001                 -0.330037                   -0.886045   \n",
       "VAOAD009                 -0.334936                   -0.802118   \n",
       "OAD001                   -0.589028                   -1.535141   \n",
       "VAOAD004                  0.449897                    0.489189   \n",
       "VAOAD011                  0.419748                    0.429119   \n",
       "\n",
       "          H_Delta_Methyldodecenoic_Acid  H_Hydroxydecanoic_acid  \\\n",
       "Study_ID                                                          \n",
       "VAOAD001                      -0.314427               -0.322677   \n",
       "VAOAD009                      -0.929470               -0.369578   \n",
       "OAD001                        -0.525277               -0.278312   \n",
       "VAOAD004                       0.413723                0.474250   \n",
       "VAOAD011                       0.333756                0.448461   \n",
       "\n",
       "          H_Hydroxydecanoate  H_Methylpentanoic_acid  \\\n",
       "Study_ID                                               \n",
       "VAOAD001           -0.650357               -0.361695   \n",
       "VAOAD009           -0.566431                0.075375   \n",
       "OAD001             -0.600484                0.019657   \n",
       "VAOAD004            0.661963                0.245553   \n",
       "VAOAD011            0.598846                0.390035   \n",
       "\n",
       "          H_Monohydroxylated_bile_acid  H_Palmitoyl_ethanolamide  \\\n",
       "Study_ID                                                           \n",
       "VAOAD001                      0.132794                 -0.067464   \n",
       "VAOAD009                     -0.519189                 -0.180631   \n",
       "OAD001                       -0.576831                 -0.901479   \n",
       "VAOAD004                      0.279290                 -0.444319   \n",
       "VAOAD011                      0.287682                 -0.532141   \n",
       "\n",
       "          H_Linoleic_Acid  \n",
       "Study_ID                   \n",
       "VAOAD001        -0.112641  \n",
       "VAOAD009        -0.418351  \n",
       "OAD001          -1.089906  \n",
       "VAOAD004        -0.912164  \n",
       "VAOAD011        -0.752280  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metabolome testing\n",
    "gdt_to_df = {}\n",
    "for g in ['saliva','stool']:\n",
    "    gdt_to_df[g] = {}\n",
    "    for d in ['paired_beta']: # just arbitrarily \n",
    "        gdt_to_df[g][d] = {}\n",
    "        df_merge = dfd_to_merge[g][d]\n",
    "        df_meta = pd.read_csv(path + 'inputs/' + g + '_normalized.csv')\n",
    "\n",
    "        # split on timepoint\n",
    "        for t in ['Baseline','After diet']:\n",
    "            df = df_meta[df_meta['Time'] == t]\n",
    "            df = df.set_index('Study_ID')\n",
    "            df.index = df.index.map(lambda x: x.split('_')[0])\n",
    "            df = df.drop('Time',axis=1)\n",
    "            gdt_to_df[g][d][t] = df\n",
    "\n",
    "        gdt_to_df[g][d]['diff'] = gdt_to_df[g][d]['After diet'] - gdt_to_df[g][d]['Baseline']\n",
    "\n",
    "gdt_to_df[g][d][t].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "572bdc64-9d32-4724-a6d6-398a44c3eccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>outcome</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>statistic</th>\n",
       "      <th>metabolite</th>\n",
       "      <th>test_stat</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>stool</td>\n",
       "      <td>VAS_Pt</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>mwu</td>\n",
       "      <td>H_Paraxanthine</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>stool</td>\n",
       "      <td>VAS_Pt</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>mwu</td>\n",
       "      <td>H_Xanthurenic_acid</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>stool</td>\n",
       "      <td>VAS_Pt</td>\n",
       "      <td>After diet</td>\n",
       "      <td>mwu</td>\n",
       "      <td>H_Kaempferol</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>stool</td>\n",
       "      <td>VAS_Pt</td>\n",
       "      <td>diff</td>\n",
       "      <td>mwu</td>\n",
       "      <td>H_Hyocholic_acid</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>stool</td>\n",
       "      <td>VAS_Pt</td>\n",
       "      <td>diff</td>\n",
       "      <td>mwu</td>\n",
       "      <td>H_Pentanoic_acid</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5487</th>\n",
       "      <td>saliva</td>\n",
       "      <td>CES_D</td>\n",
       "      <td>diff</td>\n",
       "      <td>mwu</td>\n",
       "      <td>H_Pinocembrin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>saliva</td>\n",
       "      <td>PASE_walk</td>\n",
       "      <td>diff</td>\n",
       "      <td>mwu</td>\n",
       "      <td>H_N_Acetylmuramic_Acid</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.034965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6459</th>\n",
       "      <td>saliva</td>\n",
       "      <td>PASE_light</td>\n",
       "      <td>After diet</td>\n",
       "      <td>mwu</td>\n",
       "      <td>H_PE(20:4/0:0)_[M+H]+_C25H45N1O7P1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.008159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477</th>\n",
       "      <td>saliva</td>\n",
       "      <td>PASE_light</td>\n",
       "      <td>diff</td>\n",
       "      <td>mwu</td>\n",
       "      <td>H_N_Acetylneuraminic_Acid</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.034965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6513</th>\n",
       "      <td>saliva</td>\n",
       "      <td>PASE_light</td>\n",
       "      <td>diff</td>\n",
       "      <td>mwu</td>\n",
       "      <td>H_PC(20:3/0:0)_[M+H]+_C28H53N1O7P1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.013986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       group     outcome   timepoint statistic  \\\n",
       "101    stool      VAS_Pt    Baseline       mwu   \n",
       "103    stool      VAS_Pt    Baseline       mwu   \n",
       "215    stool      VAS_Pt  After diet       mwu   \n",
       "275    stool      VAS_Pt        diff       mwu   \n",
       "283    stool      VAS_Pt        diff       mwu   \n",
       "...      ...         ...         ...       ...   \n",
       "5487  saliva       CES_D        diff       mwu   \n",
       "6334  saliva   PASE_walk        diff       mwu   \n",
       "6459  saliva  PASE_light  After diet       mwu   \n",
       "6477  saliva  PASE_light        diff       mwu   \n",
       "6513  saliva  PASE_light        diff       mwu   \n",
       "\n",
       "                              metabolite  test_stat      pval  \n",
       "101                       H_Paraxanthine        0.0  0.028571  \n",
       "103                   H_Xanthurenic_acid       16.0  0.028571  \n",
       "215                         H_Kaempferol        0.0  0.028571  \n",
       "275                     H_Hyocholic_acid        0.0  0.028571  \n",
       "283                     H_Pentanoic_acid        0.0  0.028571  \n",
       "...                                  ...        ...       ...  \n",
       "5487                       H_Pinocembrin        0.0  0.015873  \n",
       "6334              H_N_Acetylmuramic_Acid       36.0  0.034965  \n",
       "6459  H_PE(20:4/0:0)_[M+H]+_C25H45N1O7P1        3.0  0.008159  \n",
       "6477           H_N_Acetylneuraminic_Acid       36.0  0.034965  \n",
       "6513  H_PC(20:3/0:0)_[M+H]+_C28H53N1O7P1       38.0  0.013986  \n",
       "\n",
       "[89 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# differnetial metabolome profiling\n",
    "gs = []\n",
    "os = []\n",
    "ts = []\n",
    "stats = []\n",
    "xs = []\n",
    "ss = []\n",
    "ps = []\n",
    "\n",
    "arr = [gs,os,ts,stats,xs,ss,ps]\n",
    "\n",
    "for g in ['stool','saliva']:\n",
    "    for d in ['paired_beta']:\n",
    "        # test before and after\n",
    "        for tp in ['diff']:\n",
    "            #df = gdt_to_df['stool']['paired_beta']['diff']\n",
    "            df = gdt_to_df[g][d][tp].copy()\n",
    "            df_map = dfd_to_merge[g + '_adh'][d]\n",
    "            df = df.dropna(axis=0,how='all')\n",
    "            #df_map.index = df_map.index.map(lambda x: x.split('.')[0].replace('-',''))\n",
    "            #df = pd.concat([df_map['WOMAC_pain_quartiles'],df],axis=1)\n",
    "            for x in list(df.columns.values):\n",
    "                t, p = scipy.stats.ttest_1samp(df[x].values, popmean=0,nan_policy='omit')\n",
    "                arr = append_results(arr, [g,d,'post-pre','pairedt',x,t,p])\n",
    "\n",
    "                if p<0.05:\n",
    "                    df_post = gdt_to_df[g][d]['After diet'].copy() #.rename(columns={x: x + '_post'}, inplace=True)\n",
    "                    df_post['Timepoint'] = 'post'\n",
    "                    df_pre = gdt_to_df[g][d]['Baseline'].copy() # .rename(columns={x: x + '_pre'}, inplace=True)\n",
    "                    df_pre['Timepoint'] = 'pre'\n",
    "                    \n",
    "                    df_plot = pd.concat([df_post, df_pre], axis=0)\n",
    "                    sns.boxplot(data=df_plot, x='Timepoint', y=x)\n",
    "                    sns.swarmplot(data=df_plot, x='Timepoint', y=x, color='black')\n",
    "                    sns.despine()\n",
    "                \n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(path + 'outputs/Qiime2_' + g + '/meta_' + x.replace('/','fslash') + '_differential.pdf')\n",
    "                    plt.close()    \n",
    "\n",
    "        \n",
    "        for o in outcomes:\n",
    "            # build expandable arrays; first get possible values of outcome\n",
    "            outcome_var = o + '_quartiles'\n",
    "            df_map = dfd_to_merge[g + '_adh'][d][outcome_var]\n",
    "            # drop na\n",
    "            df_map = df_map.dropna(how='any')\n",
    "            values = list(df_map.unique())\n",
    "\n",
    "            for t in ['Baseline','After diet','diff']:\n",
    "                # merge with pre post or diff metabolome data\n",
    "                df = pd.concat([df_map, gdt_to_df[g][d][t]],axis=1)\n",
    "            \n",
    "                # remove outcome var from iterations\n",
    "                df_x = df.drop(outcome_var,axis=1)\n",
    "                for x in list(df_x.columns.values):\n",
    "                    df_test = df.loc[:,[outcome_var,x]]\n",
    "                    #arr_list = [list(df_test.groupby([outcome_var]).get_group(values[i])[x].values) for i in range(len(values))]\n",
    "                \n",
    "                    #W, p = scipy.stats.kruskal(*arr_list)#, nan_policy='omit')\n",
    "                    u, p = scipy.stats.mannwhitneyu(df_test[df_test[outcome_var] == 'top'][x].values, \n",
    "                                                    df_test[df_test[outcome_var] == 'bottom'][x].values, \n",
    "                                                    nan_policy='omit')\n",
    "                            \n",
    "                    if p<0.05:\n",
    "                        sns.boxplot(data=df_test, x=outcome_var, y=x)\n",
    "                        sns.swarmplot(data=df_test, x=outcome_var, y=x, color='black')\n",
    "                        sns.despine()\n",
    "                    \n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig(path + 'outputs/Qiime2_' + g + '/meta_' + x.replace('/','fslash') + '_' + t + '_' + o + '.pdf')\n",
    "                        plt.close()    \n",
    "\n",
    "                    # arr = append_results(arr, [g,o,t,'kw',x,u,p])\n",
    "                    arr = append_results(arr, [g,o,t,'mwu',x,u,p])\n",
    "        \n",
    "\n",
    "df_results = pd.DataFrame.from_dict({\n",
    "    'group': gs,\n",
    "    'outcome': os,\n",
    "    'timepoint': ts,\n",
    "    'statistic': stats,\n",
    "    'metabolite': xs,\n",
    "    'test_stat': ss,\n",
    "    'pval': ps\n",
    "})\n",
    "df_results.to_csv(path + 'outputs/df_results_meta_diff.tsv', sep='\\t')\n",
    "\n",
    "# df_results.head()\n",
    "# df = df_results[df_results['statistic'] == 'kw']\n",
    "df = df_results[df_results['statistic'] == 'mwu']\n",
    "df[df['pval'] < 0.05]\n",
    "\n",
    "#df = df_results[df_results['statistic'] == 'kw']\n",
    "#df = df.dropna(subset='pval')\n",
    "#df['FDR_bh'] = scipy.stats.false_discovery_control(df['pval'].values)\n",
    "#df = df[df['FDR_bh'] < 0.05]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63b0295-49c7-4525-b14e-d73dbaf81490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# differential metabolites post vs pre\n",
    "df = df_results[df_results['pval'] < 0.05]\n",
    "df = df[df['statistic'] == 'pairedt']\n",
    "# df = df[df['outcome'].isin(['VAS_Pt','WOMAC_pain'])]\n",
    "print(len(df))\n",
    "# df.head()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5699b-8d26-478d-ac5a-d5eee7cf4789",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['pval'] < 0.05]\n",
    "df[df['outcome'].isin(['VAS_Pt','WOMAC_pain'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8e0ee0-93f2-4f45-9f7e-15f2dbc8bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform random forest \n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict,  KFold,  LeaveOneOut, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "for g in ['stool','saliva']:\n",
    "    print(g)\n",
    "    for d in ['paired_beta']:\n",
    "        # test before and after\n",
    "        for t in ['diff']:\n",
    "            # diagnosis = df_num['BinDiag']\n",
    "            df = gdt_to_df[g][d][t]\n",
    "            df_map = dfd_to_merge[g + '_adh'][d]\n",
    "            outcome_var = 'VAS_Pt' + '_quartiles'\n",
    "            df = pd.concat([df_map[outcome_var], df], axis=1)\n",
    "            df = df.dropna(how='any',axis=0)\n",
    "            df = df[df[outcome_var].isin(['top','bottom'])]\n",
    "            df[outcome_var] = (df[outcome_var] == 'bottom').astype(int)\n",
    "            \n",
    "            # get columns of interest\n",
    "            features = [x.strip() for x in list(df.columns.values)]\n",
    "            \n",
    "            # subset df_rf\n",
    "            df = df[features]\n",
    "                        \n",
    "            # separate data and labels\n",
    "            X, y = df.drop(outcome_var,axis=1).values, df[outcome_var].values\n",
    "            \n",
    "            # set fold split\n",
    "            kf = LeaveOneOut()\n",
    "            # kf = KFold(n_splits=3)\n",
    "            \n",
    "            # try SVC\n",
    "            # clf = SVC(kernel='linear', class_weight='balanced', probability=True, random_state=42)\n",
    "            clf = SVC(probability=True, random_state=42)\n",
    "            all_y = []\n",
    "            all_probs=[]\n",
    "            for train, test in kf.split(X, y):\n",
    "                all_y.append(y[test])\n",
    "                all_probs.append(clf.fit(X[train], y[train]).predict_proba(X[test])[:,1])\n",
    "            all_y = np.array(all_y)\n",
    "            all_probs = np.array(all_probs)\n",
    "            \n",
    "            fpr, tpr, thresholds = roc_curve(all_y,all_probs)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            print('SVC')\n",
    "            print(roc_auc)\n",
    "                \n",
    "            # try RF\n",
    "            # clf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "            clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            all_y = []\n",
    "            all_probs=[]\n",
    "            for train, test in kf.split(X, y):\n",
    "                all_y.append(y[test])\n",
    "                all_probs.append(clf.fit(X[train], y[train]).predict_proba(X[test])[:,1])\n",
    "            all_y = np.array(all_y)\n",
    "            all_probs = np.array(all_probs)\n",
    "            \n",
    "            fpr, tpr, thresholds = roc_curve(all_y,all_probs)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            print('RF')\n",
    "            print(roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb1a97-0633-4567-84a3-c801f85e9dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial correlation\n",
    "outcome_var = 'VAS_Pt' + '_quartiles'\n",
    "outcome_var = 'VAS_Pt'\n",
    "\n",
    "for g in ['stool','saliva']:\n",
    "    print(g)\n",
    "    for d in ['paired_beta']:\n",
    "        # test before and after\n",
    "        for t in ['diff']:\n",
    "            # diagnosis = df_num['BinDiag']\n",
    "            df = gdt_to_df[g][d][t]\n",
    "            df_map = dfd_to_merge[g + '_adh'][d]\n",
    "            df = pd.concat([df_map[outcome_var], df], axis=1)\n",
    "            df = df.dropna(how='any',axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af265f0-151a-4d4d-8d4c-f8ee8678bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "import re\n",
    "df = df.copy()\n",
    "#df = df.rename(columns = lambda x: x.replace(':', 'bc'))\n",
    "#df = df.rename(columns = lambda x: x.replace(' ', 'space'))\n",
    "#df = df.rename(columns = lambda x: x.replace('/', 'fs'))\n",
    "#df = df.rename(columns = lambda x: x.replace('(', 'fp'))\n",
    "#df = df.rename(columns = lambda x: x.replace(')', 'bp'))\n",
    "#df = df.rename(columns = lambda x: x.replace('.', 'p'))\n",
    "#df = df.rename(columns = lambda x: x.replace('_', 'us'))\n",
    "#df = df.rename(columns = lambda x: x.replace('[', 'fb'))\n",
    "# df = df.rename(columns = lambda x: x.replace(']', 'bb'))\n",
    "df = df.rename(columns = lambda x: re.sub(r'\\W+', '', x))\n",
    "\n",
    "indep = list(df.columns.values)[1]\n",
    "for x in list(df.columns.values)[2:]:\n",
    "    indep = indep + ' + ' + x\n",
    "formula = str(outcome_var) + ' ~ ' + indep # \"A ~ B + C\"\n",
    "result = sm.ols(formula=formula, data=df).fit()\n",
    "# print(result.params)\n",
    "# print(result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9178b8-4227-4ad6-93ec-b3f75f704e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "X, Y = df.iloc[:,1:], df.iloc[:,0]\n",
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(X, Y)\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c652c773-a126-44c9-aa01-05a07992d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.DataFrame.from_dict({'var':list(df.columns.values)[1:],'coef':clf.coef_})\n",
    "tdf[tdf['coef'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308287d-4650-471f-8a49-5f15adc258bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#rng = np.random.RandomState(0)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=rng)\n",
    "X_train, X_test, y_train, y_test = X, X, Y, Y\n",
    "\n",
    "pcr = make_pipeline(StandardScaler(), PCA(n_components=1), LinearRegression())\n",
    "pcr.fit(X_train, y_train)\n",
    "pca = pcr.named_steps[\"pca\"]  # retrieve the PCA step of the pipeline\n",
    "\n",
    "pls = PLSRegression(n_components=1)\n",
    "pls.fit(X_train, y_train)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "axes[0].scatter(pca.transform(X_test), y_test, alpha=0.3, label=\"ground truth\")\n",
    "axes[0].scatter(\n",
    "    pca.transform(X_test), pcr.predict(X_test), alpha=0.3, label=\"predictions\"\n",
    ")\n",
    "axes[0].set(\n",
    "    xlabel=\"Projected data onto first PCA component\", ylabel=\"y\", title=\"PCR / PCA\"\n",
    ")\n",
    "axes[0].legend()\n",
    "axes[1].scatter(pls.transform(X_test), y_test, alpha=0.3, label=\"ground truth\")\n",
    "axes[1].scatter(\n",
    "    pls.transform(X_test), pls.predict(X_test), alpha=0.3, label=\"predictions\"\n",
    ")\n",
    "axes[1].set(xlabel=\"Projected data onto first PLS component\", ylabel=\"y\", title=\"PLS\")\n",
    "axes[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"PCR r-squared {pcr.score(X_test, y_test):.3f}\")\n",
    "print(f\"PLS r-squared {pls.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbc5009-cb76-45d8-b3b2-4a0ce7620350",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2 = make_pipeline(PCA(n_components=2), LinearRegression())\n",
    "pca_2.fit(X_train, y_train)\n",
    "print(f\"PCR r-squared with 2 components {pca_2.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9bd4bb-68a2-4cd3-8646-1a9d74f713e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pls.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aa7b98-67d0-4e52-af09-3c86264c45b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for iMic\n",
    "df = pd.read_csv(path + 'outputs/Qiime2_stool_adh/level-6.csv', index_col=0)\n",
    "\n",
    "# filter out metadata\n",
    "for x in list(df.columns.values):\n",
    "    if 'k__' not in x:\n",
    "        df = df.drop(x,axis=1)\n",
    "\n",
    "# normalize to 0-1\n",
    "df = df.div(df.sum(axis=1),axis=0).T\n",
    "\n",
    "df.to_csv(path + 'outputs/Qiime2_stool_adh/otu_table_L6.csv',index_label=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2193443-d92a-4a67-b9bb-81caf3e9c4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
